{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd8d0c0-2c2d-4751-8f5d-999d79ae6108",
   "metadata": {},
   "source": [
    "## Convert video to text with Speech-to-text model and sentence embedding model\n",
    "\n",
    "In this notebook, we will extract information from video/audio files with [Whipser model](https://github.com/openai/whisper). Be leveraging multilingual support, we can extract tanscripts from videos files mixed different languages, even for one video file with different languanges. We provide the following options for whisper inference:\n",
    "- Batch inference with SageMaker Processing job, we can process massive data and store them into vector database for RAG solution.\n",
    "- Real-time inference with SageMaker Endpoint, we can leverage it to do summarizaton or QA with a short video/audio file (less than 6MB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a02764-403f-4c35-9754-e99e2a8d5b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38922488-e64f-45e2-983a-5c176f4e13ab",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c209ddd-7a9a-4c7c-b582-6729ce88a4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceProcessor\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"sagemaker/rag_video\"\n",
    "folder_name = \"genai_workshop\"\n",
    "s3_input = f\"s3://{bucket}/{prefix}/raw_data/{folder_name}\" # Directory for video files\n",
    "s3_output_clips = f\"s3://{bucket}/{prefix}/clips\" # Directory for video clips\n",
    "s3_output_transcript = f\"s3://{bucket}/{prefix}/transcript\" # Directory for transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892e7ff-edfe-4112-9ccd-bc34b2fc1bde",
   "metadata": {},
   "source": [
    "## Upload test data to S3 bucket\n",
    "\n",
    "Download data from YouTube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388a7d5d-eeaa-48bd-9b5b-9a352489cc89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pytube in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (15.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Download data from YouTube\n",
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5eee50a-9c66-456b-879f-98a09d85d87e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "VIDEO_SAVE_DIRECTORY = \"./videos\"\n",
    "AUDIO_SAVE_DIRECTORY = \"./audio\"\n",
    "\n",
    "def download(video_url):\n",
    "    video = YouTube(video_url)\n",
    "    video = video.streams.get_highest_resolution()\n",
    "\n",
    "    try:\n",
    "        video.download(VIDEO_SAVE_DIRECTORY)\n",
    "    except:\n",
    "        print(\"Failed to download video\")\n",
    "\n",
    "    print(\"video was downloaded successfully\")\n",
    "    \n",
    "def download_audio(video_url):\n",
    "    video = YouTube(video_url)\n",
    "    audio = video.streams.filter(only_audio = True).first()\n",
    "\n",
    "    try:\n",
    "        audio.download(AUDIO_SAVE_DIRECTORY)\n",
    "    except:\n",
    "        print(\"Failed to download audio\")\n",
    "\n",
    "    print(\"audio was downloaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4888c5f4-52a0-4b3d-95e5-0bd0cca84af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JAWS-UG AI/ML (Japanese) #16 Generative AI: https://www.youtube.com/watch?v=PkZenNAXtYs\n",
    "# New York Summit 2023 AIML: https://www.youtube.com/watch?v=1PkABWCJINM Totally 36mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e6fe10-3eed-4578-b4ad-7b4e044f84a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video was downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "download(\"https://www.youtube.com/watch?v=dBzCGcwYCJo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02daea10-0cbf-4f5d-b294-023f6d56b12f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: videos/genai_interview.mp4 to s3://sagemaker-us-east-1-822507008821/sagemaker/rag_video/raw_data/genai_workshop/genai_interview.mp4\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp videos/genai_interview.mp4 {s3_input}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00c2e3-c897-4a2c-a12e-b07c75ca5986",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch inference with SageMaker Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e002118-b7dc-4915-9fe0-f80e3bbfe847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "hfp = HuggingFaceProcessor(\n",
    "    role=get_execution_role(), \n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    transformers_version='4.28.1',\n",
    "    pytorch_version='2.0.0', \n",
    "    base_job_name='frameworkprocessor-hf',\n",
    "    py_version=\"py310\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90383250-179b-4499-8583-fdca5320ee75",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded data_preparation to s3://sagemaker-us-east-1-822507008821/frameworkprocessor-hf-2023-07-27-16-26-16-160/source/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-822507008821/frameworkprocessor-hf-2023-07-27-16-26-16-160/source/runproc.sh\n",
      "INFO:sagemaker:Creating processing-job with name frameworkprocessor-hf-2023-07-27-16-26-16-160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "...........................................................\u001b[34mWARNING: Skipping typing as it is not installed.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting git+https://github.com/openai/whisper.git (from -r requirements.txt (line 3))\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-mofi4hkv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-mofi4hkv\n",
      "  Resolved https://github.com/openai/whisper.git to commit b91c907694f96a3fb9da03d4bbdc83fbcd3a40a4\n",
      "  Installing build dependencies: started\u001b[0m\n",
      "\u001b[34m  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from -r requirements.txt (line 1))\n",
      "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 34.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting moviepy (from -r requirements.txt (line 2))\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 388.3/388.3 kB 34.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.154.0)\u001b[0m\n",
      "\u001b[34mCollecting pydub (from -r requirements.txt (line 5))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mCollecting sentence-transformers (from -r requirements.txt (line 6))\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 16.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting decorator<5.0,>=4.0.2 (from moviepy->-r requirements.txt (line 2))\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy->-r requirements.txt (line 2)) (4.65.0)\u001b[0m\n",
      "\u001b[34mCollecting proglog<=1.0.0 (from moviepy->-r requirements.txt (line 2))\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy->-r requirements.txt (line 2)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy->-r requirements.txt (line 2)) (2.28.1)\u001b[0m\n",
      "\u001b[34mCollecting imageio_ffmpeg>=0.2.0 (from moviepy->-r requirements.txt (line 2))\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.9/26.9 MB 50.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting triton==2.0.0 (from openai-whisper==20230314->-r requirements.txt (line 3))\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.3/63.3 MB 27.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314->-r requirements.txt (line 3)) (0.56.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314->-r requirements.txt (line 3)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting more-itertools (from openai-whisper==20230314->-r requirements.txt (line 3))\n",
      "  Downloading more_itertools-10.0.0-py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.3/55.3 kB 8.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from -r requirements.txt (line 1))\n",
      "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 66.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314->-r requirements.txt (line 3)) (3.26.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314->-r requirements.txt (line 3)) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314->-r requirements.txt (line 3)) (16.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3<2.0,>=1.26.28 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (1.26.132)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (3.20.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (4.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML==5.4.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (4.17.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (1.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (0.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (1.10.1)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from sentence-transformers->-r requirements.txt (line 6))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 70.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (0.1.99)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (0.14.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.30.0,>=1.29.132 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 4)) (1.29.132)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 4)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 6)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 6)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy->-r requirements.txt (line 2)) (9.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker->-r requirements.txt (line 4)) (3.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 3)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 3)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 3)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->-r requirements.txt (line 6)) (0.13.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 4)) (0.19.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers->-r requirements.txt (line 6)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers->-r requirements.txt (line 6)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20230314->-r requirements.txt (line 3)) (0.39.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20230314->-r requirements.txt (line 3)) (65.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker->-r requirements.txt (line 4)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker->-r requirements.txt (line 4)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker->-r requirements.txt (line 4)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 4)) (1.7.6.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 4)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 4)) (0.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 4)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker->-r requirements.txt (line 4)) (21.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 6)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20230314->-r requirements.txt (line 3)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20230314->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: moviepy, openai-whisper, sentence-transformers\n",
      "  Building wheel for moviepy (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for moviepy (setup.py): finished with status 'done'\n",
      "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110730 sha256=efb37fce6903dd620ab5e177ba5f573edfb4b7d959553e3529f6a4b7756ed4af\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\u001b[0m\n",
      "\u001b[34m  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798283 sha256=3f2ec9fe8adc66c52e76540cca34250f6985a6acf5a7b55d1504a9ef8040f71f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-f9cq_ghz/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=1b1b7c9ee7b6bfeab8504ca1301be8df7c3251de6d7b53f7809c68d14a7903c7\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\u001b[0m\n",
      "\u001b[34mSuccessfully built moviepy openai-whisper sentence-transformers\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pydub, proglog, nltk, more-itertools, imageio_ffmpeg, decorator, tiktoken, moviepy, triton, sentence-transformers, openai-whisper\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled decorator-5.1.1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0.dev20221202\n",
      "    Uninstalling triton-2.0.0.dev20221202:\n",
      "      Successfully uninstalled triton-2.0.0.dev20221202\u001b[0m\n",
      "\u001b[34mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.8 more-itertools-10.0.0 moviepy-1.0.3 nltk-3.8.1 openai-whisper-20230314 proglog-0.1.10 pydub-0.25.1 sentence-transformers-2.2.2 tiktoken-0.3.3 triton-2.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.2.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m#015Downloading (…)lve/main/config.json:   0%|          | 0.00/1.99k [00:00<?, ?B/s]#015Downloading (…)lve/main/config.json: 100%|██████████| 1.99k/1.99k [00:00<00:00, 10.6MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading pytorch_model.bin:   0%|          | 0.00/6.17G [00:00<?, ?B/s]#015Downloading pytorch_model.bin:   1%|          | 41.9M/6.17G [00:00<00:20, 302MB/s]#015Downloading pytorch_model.bin:   1%|          | 73.4M/6.17G [00:00<00:19, 308MB/s]#015Downloading pytorch_model.bin:   2%|▏         | 105M/6.17G [00:00<00:20, 301MB/s] #015Downloading pytorch_model.bin:   2%|▏         | 147M/6.17G [00:00<00:19, 310MB/s]#015Downloading pytorch_model.bin:   3%|▎         | 178M/6.17G [00:00<00:19, 305MB/s]#015Downloading pytorch_model.bin:   4%|▎         | 220M/6.17G [00:00<00:18, 316MB/s]#015Downloading pytorch_model.bin:   4%|▍         | 262M/6.17G [00:00<00:18, 314MB/s]#015Downloading pytorch_model.bin:   5%|▍         | 304M/6.17G [00:00<00:18, 319MB/s]#015Downloading pytorch_model.bin:   6%|▌         | 346M/6.17G [00:01<00:17, 330MB/s]#015Downloading pytorch_model.bin:   6%|▋         | 388M/6.17G [00:01<00:17, 340MB/s]#015Downloading pytorch_model.bin:   7%|▋         | 430M/6.17G [00:01<00:17, 336MB/s]#015Downloading pytorch_model.bin:   8%|▊         | 472M/6.17G [00:01<00:17, 324MB/s]#015Downloading pytorch_model.bin:   8%|▊         | 514M/6.17G [00:01<00:17, 324MB/s]#015Downloading pytorch_model.bin:   9%|▉         | 556M/6.17G [00:01<00:17, 324MB/s]#015Downloading pytorch_model.bin:  10%|▉         | 598M/6.17G [00:01<00:16, 329MB/s]#015Downloading pytorch_model.bin:  10%|█         | 640M/6.17G [00:01<00:17, 317MB/s]#015Downloading pytorch_model.bin:  11%|█         | 682M/6.17G [00:02<00:16, 325MB/s]#015Downloading pytorch_model.bin:  12%|█▏        | 724M/6.17G [00:02<00:17, 316MB/s]#015Downloading pytorch_model.bin:  12%|█▏        | 765M/6.17G [00:02<00:17, 316MB/s]#015Downloading pytorch_model.bin:  13%|█▎        | 807M/6.17G [00:02<00:17, 314MB/s]#015Downloading pytorch_model.bin:  14%|█▍        | 849M/6.17G [00:02<00:18, 292MB/s]#015Downloading pytorch_model.bin:  14%|█▍        | 881M/6.17G [00:02<00:18, 289MB/s]#015Downloading pytorch_model.bin:  15%|█▍        | 912M/6.17G [00:02<00:17, 294MB/s]#015Downloading pytorch_model.bin:  15%|█▌        | 944M/6.17G [00:03<00:17, 294MB/s]#015Downloading pytorch_model.bin:  16%|█▌        | 986M/6.17G [00:03<00:17, 302MB/s]#015Downloading pytorch_model.bin:  17%|█▋        | 1.03G/6.17G [00:03<00:16, 310MB/s]#015Downloading pytorch_model.bin:  17%|█▋        | 1.07G/6.17G [00:03<00:16, 311MB/s]#015Downloading pytorch_model.bin:  18%|█▊        | 1.10G/6.17G [00:03<00:16, 305MB/s]#015Downloading pytorch_model.bin:  18%|█▊        | 1.13G/6.17G [00:03<00:16, 304MB/s]#015Downloading pytorch_model.bin:  19%|█▉        | 1.16G/6.17G [00:03<00:16, 299MB/s]#015Downloading pytorch_model.bin:  19%|█▉        | 1.20G/6.17G [00:03<00:16, 296MB/s]#015Downloading pytorch_model.bin:  20%|██        | 1.24G/6.17G [00:03<00:16, 305MB/s]#015Downloading pytorch_model.bin:  21%|██        | 1.28G/6.17G [00:04<00:15, 307MB/s]#015Downloading pytorch_model.bin:  21%|██▏       | 1.32G/6.17G [00:04<00:15, 316MB/s]#015Downloading pytorch_model.bin:  22%|██▏       | 1.36G/6.17G [00:04<00:15, 316MB/s]#015Downloading pytorch_model.bin:  23%|██▎       | 1.41G/6.17G [00:04<00:14, 320MB/s]#015Downloading pytorch_model.bin:  23%|██▎       | 1.45G/6.17G [00:04<00:14, 321MB/s]#015Downloading pytorch_model.bin:  24%|██▍       | 1.49G/6.17G [00:04<00:14, 313MB/s]#015Downloading pytorch_model.bin:  25%|██▍       | 1.52G/6.17G [00:04<00:15, 308MB/s]#015Downloading pytorch_model.bin:  25%|██▌       | 1.55G/6.17G [00:04<00:14, 309MB/s]#015Downloading pytorch_model.bin:  26%|██▌       | 1.58G/6.17G [00:05<00:15, 306MB/s]#015Downloading pytorch_model.bin:  26%|██▌       | 1.61G/6.17G [00:05<00:15, 304MB/s]#015Downloading pytorch_model.bin:  27%|██▋       | 1.66G/6.17G [00:05<00:14, 310MB/s]#015Downloading pytorch_model.bin:  28%|██▊       | 1.70G/6.17G [00:05<00:14, 317MB/s]#015Downloading pytorch_model.bin:  28%|██▊       | 1.74G/6.17G [00:05<00:13, 323MB/s]#015Downloading pytorch_model.bin:  29%|██▉       | 1.78G/6.17G [00:05<00:13, 324MB/s]#015Downloading pytorch_model.bin:  30%|██▉       | 1.82G/6.17G [00:05<00:13, 314MB/s]#015Downloading pytorch_model.bin:  30%|███       | 1.87G/6.17G [00:05<00:14, 304MB/s]#015Downloading pytorch_model.bin:  31%|███       | 1.90G/6.17G [00:06<00:14, 292MB/s]#015Downloading pytorch_model.bin:  31%|███▏      | 1.93G/6.17G [00:06<00:14, 290MB/s]#015Downloading pytorch_model.bin:  32%|███▏      | 1.96G/6.17G [00:06<00:14, 292MB/s]#015Downloading pytorch_model.bin:  32%|███▏      | 1.99G/6.17G [00:06<00:14, 296MB/s]#015Downloading pytorch_model.bin:  33%|███▎      | 2.03G/6.17G [00:06<00:13, 306MB/s]#015Downloading pytorch_model.bin:  34%|███▎      | 2.08G/6.17G [00:06<00:13, 308MB/s]#015Downloading pytorch_model.bin:  34%|███▍      | 2.11G/6.17G [00:06<00:13, 306MB/s]#015Downloading pytorch_model.bin:  35%|███▍      | 2.14G/6.17G [00:06<00:13, 302MB/s]#015Downloading pytorch_model.bin:  35%|███▌      | 2.17G/6.17G [00:07<00:13, 301MB/s]#015Downloading pytorch_model.bin:  36%|███▌      | 2.20G/6.17G [00:07<00:13, 297MB/s]#015Downloading pytorch_model.bin:  36%|███▋      | 2.24G/6.17G [00:07<00:12, 307MB/s]#015Downloading pytorch_model.bin:  37%|███▋      | 2.29G/6.17G [00:07<00:12, 313MB/s]#015Downloading pytorch_model.bin:  38%|███▊      | 2.33G/6.17G [00:07<00:12, 316MB/s]#015Downloading pytorch_model.bin:  38%|███▊      | 2.37G/6.17G [00:07<00:12, 317MB/s]#015Downloading pytorch_model.bin:  39%|███▉      | 2.41G/6.17G [00:07<00:11, 321MB/s]#015Downloading pytorch_model.bin:  40%|███▉      | 2.45G/6.17G [00:07<00:11, 324MB/s]#015Downloading pytorch_model.bin:  40%|████      | 2.50G/6.17G [00:08<00:11, 327MB/s]#015Downloading pytorch_model.bin:  41%|████      | 2.54G/6.17G [00:08<00:10, 332MB/s]#015Downloading pytorch_model.bin:  42%|████▏     | 2.58G/6.17G [00:08<00:11, 317MB/s]#015Downloading pytorch_model.bin:  42%|████▏     | 2.62G/6.17G [00:08<00:11, 315MB/s]#015Downloading pytorch_model.bin:  43%|████▎     | 2.66G/6.17G [00:08<00:11, 316MB/s]#015Downloading pytorch_model.bin:  44%|████▍     | 2.71G/6.17G [00:08<00:10, 321MB/s]#015Downloading pytorch_model.bin:  45%|████▍     | 2.75G/6.17G [00:08<00:10, 319MB/s]#015Downloading pytorch_model.bin:  45%|████▌     | 2.79G/6.17G [00:08<00:10, 321MB/s]#015Downloading pytorch_model.bin:  46%|████▌     | 2.83G/6.17G [00:09<00:10, 322MB/s]#015Downloading pytorch_model.bin:  47%|████▋     | 2.87G/6.17G [00:09<00:10, 322MB/s]#015Downloading pytorch_model.bin:  47%|████▋     | 2.92G/6.17G [00:09<00:09, 331MB/s]#015Downloading pytorch_model.bin:  48%|████▊     | 2.96G/6.17G [00:09<00:09, 329MB/s]#015Downloading pytorch_model.bin:  49%|████▊     | 3.00G/6.17G [00:09<00:09, 323MB/s]#015Downloading pytorch_model.bin:  49%|████▉     | 3.04G/6.17G [00:09<00:09, 329MB/s]#015Downloading pytorch_model.bin:  50%|████▉     | 3.08G/6.17G [00:09<00:09, 321MB/s]#015Downloading pytorch_model.bin:  51%|█████     | 3.12G/6.17G [00:09<00:09, 321MB/s]#015Downloading pytorch_model.bin:  51%|█████▏    | 3.17G/6.17G [00:10<00:09, 313MB/s]#015Downloading pytorch_model.bin:  52%|█████▏    | 3.20G/6.17G [00:10<00:09, 304MB/s]#015Downloading pytorch_model.bin:  52%|█████▏    | 3.24G/6.17G [00:10<00:09, 312MB/s]#015Downloading pytorch_model.bin:  53%|█████▎    | 3.28G/6.17G [00:10<00:09, 320MB/s]#015Downloading pytorch_model.bin:  54%|█████▍    | 3.32G/6.17G [00:10<00:08, 326MB/s]#015Downloading pytorch_model.bin:  55%|█████▍    | 3.37G/6.17G [00:10<00:08, 328MB/s]#015Downloading pytorch_model.bin:  55%|█████▌    | 3.41G/6.17G [00:10<00:08, 335MB/s]#015Downloading pytorch_model.bin:  56%|█████▌    | 3.45G/6.17G [00:10<00:08, 325MB/s]#015Downloading pytorch_model.bin:  57%|█████▋    | 3.49G/6.17G [00:11<00:08, 324MB/s]#015Downloading pytorch_model.bin:  57%|█████▋    | 3.53G/6.17G [00:11<00:08, 321MB/s]#015Downloading pytorch_model.bin:  58%|█████▊    | 3.58G/6.17G [00:11<00:07, 326MB/s]#015Downloading pytorch_model.bin:  59%|█████▊    | 3.62G/6.17G [00:11<00:07, 328MB/s]#015Downloading pytorch_model.bin:  59%|█████▉    | 3.66G/6.17G [00:11<00:08, 299MB/s]#015Downloading pytorch_model.bin:  60%|█████▉    | 3.69G/6.17G [00:11<00:08, 293MB/s]#015Downloading pytorch_model.bin:  60%|██████    | 3.72G/6.17G [00:11<00:08, 292MB/s]#015Downloading pytorch_model.bin:  61%|██████    | 3.76G/6.17G [00:12<00:07, 306MB/s]#015Downloading pytorch_model.bin:  61%|██████▏   | 3.80G/6.17G [00:12<00:07, 299MB/s]#015Downloading pytorch_model.bin:  62%|██████▏   | 3.83G/6.17G [00:12<00:08, 292MB/s]#015Downloading pytorch_model.bin:  63%|██████▎   | 3.86G/6.17G [00:12<00:07, 298MB/s]#015Downloading pytorch_model.bin:  63%|██████▎   | 3.90G/6.17G [00:12<00:07, 311MB/s]#015Downloading pytorch_model.bin:  64%|██████▍   | 3.94G/6.17G [00:12<00:06, 321MB/s]#015Downloading pytorch_model.bin:  65%|██████▍   | 3.98G/6.17G [00:12<00:06, 318MB/s]#015Downloading pytorch_model.bin:  65%|██████▌   | 4.03G/6.17G [00:12<00:06, 317MB/s]#015Downloading pytorch_model.bin:  66%|██████▌   | 4.07G/6.17G [00:12<00:06, 313MB/s]#015Downloading pytorch_model.bin:  66%|██████▋   | 4.10G/6.17G [00:13<00:06, 307MB/s]#015Downloading pytorch_model.bin:  67%|██████▋   | 4.13G/6.17G [00:13<00:06, 300MB/s]#015Downloading pytorch_model.bin:  67%|██████▋   | 4.16G/6.17G [00:13<00:06, 298MB/s]#015Downloading pytorch_model.bin:  68%|██████▊   | 4.19G/6.17G [00:13<00:06, 295MB/s]#015Downloading pytorch_model.bin:  68%|██████▊   | 4.23G/6.17G [00:13<00:06, 298MB/s]#015Downloading pytorch_model.bin:  69%|██████▉   | 4.27G/6.17G [00:13<00:06, 307MB/s]#015Downloading pytorch_model.bin:  70%|██████▉   | 4.30G/6.17G [00:13<00:06, 307MB/s]#015Downloading pytorch_model.bin:  70%|███████   | 4.33G/6.17G [00:13<00:06, 292MB/s]#015Downloading pytorch_model.bin:  71%|███████   | 4.36G/6.17G [00:13<00:06, 297MB/s]#015Downloading pytorch_model.bin:  71%|███████   | 4.39G/6.17G [00:14<00:06, 294MB/s]#015Downloading pytorch_model.bin:  72%|███████▏  | 4.44G/6.17G [00:14<00:05, 302MB/s]#015Downloading pytorch_model.bin:  73%|███████▎  | 4.48G/6.17G [00:14<00:05, 308MB/s]#015Downloading pytorch_model.bin:  73%|███████▎  | 4.52G/6.17G [00:14<00:05, 316MB/s]#015Downloading pytorch_model.bin:  74%|███████▍  | 4.56G/6.17G [00:14<00:05, 322MB/s]#015Downloading pytorch_model.bin:  75%|███████▍  | 4.60G/6.17G [00:14<00:04, 328MB/s]#015Downloading pytorch_model.bin:  75%|███████▌  | 4.65G/6.17G [00:14<00:04, 318MB/s]#015Downloading pytorch_model.bin:  76%|███████▌  | 4.69G/6.17G [00:15<00:04, 313MB/s]#015Downloading pytorch_model.bin:  76%|███████▋  | 4.72G/6.17G [00:15<00:04, 313MB/s]#015Downloading pytorch_model.bin:  77%|███████▋  | 4.75G/6.17G [00:15<00:05, 259MB/s]#015Downloading pytorch_model.bin:  77%|███████▋  | 4.78G/6.17G [00:15<00:05, 267MB/s]#015Downloading pytorch_model.bin:  78%|███████▊  | 4.81G/6.17G [00:15<00:04, 278MB/s]#015Downloading pytorch_model.bin:  78%|███████▊  | 4.84G/6.17G [00:15<00:04, 283MB/s]#015Downloading pytorch_model.bin:  79%|███████▉  | 4.88G/6.17G [00:15<00:04, 290MB/s]#015Downloading pytorch_model.bin:  80%|███████▉  | 4.92G/6.17G [00:15<00:04, 301MB/s]#015Downloading pytorch_model.bin:  80%|████████  | 4.96G/6.17G [00:15<00:03, 310MB/s]#015Downloading pytorch_model.bin:  81%|████████  | 5.00G/6.17G [00:16<00:03, 313MB/s]#015Downloading pytorch_model.bin:  82%|████████▏ | 5.04G/6.17G [00:16<00:03, 319MB/s]#015Downloading pytorch_model.bin:  82%|████████▏ | 5.09G/6.17G [00:16<00:03, 314MB/s]#015Downloading pytorch_model.bin:  83%|████████▎ | 5.13G/6.17G [00:16<00:03, 314MB/s]#015Downloading pytorch_model.bin:  84%|████████▎ | 5.17G/6.17G [00:16<00:03, 308MB/s]#015Downloading pytorch_model.bin:  84%|████████▍ | 5.20G/6.17G [00:16<00:03, 301MB/s]#015Downloading pytorch_model.bin:  85%|████████▍ | 5.23G/6.17G [00:16<00:03, 299MB/s]#015Downloading pytorch_model.bin:  85%|████████▌ | 5.27G/6.17G [00:16<00:02, 304MB/s]#015Downloading pytorch_model.bin:  86%|████████▌ | 5.32G/6.17G [00:17<00:02, 317MB/s]#015Downloading pytorch_model.bin:  87%|████████▋ | 5.36G/6.17G [00:17<00:02, 314MB/s]#015Downloading pytorch_model.bin:  87%|████████▋ | 5.40G/6.17G [00:17<00:02, 310MB/s]#015Downloading pytorch_model.bin:  88%|████████▊ | 5.44G/6.17G [00:17<00:02, 310MB/s]#015Downloading pytorch_model.bin:  89%|████████▉ | 5.48G/6.17G [00:17<00:02, 323MB/s]#015Downloading pytorch_model.bin:  90%|████████▉ | 5.53G/6.17G [00:17<00:01, 333MB/s]#015Downloading pytorch_model.bin:  90%|█████████ | 5.57G/6.17G [00:17<00:01, 334MB/s]#015Downloading pytorch_model.bin:  91%|█████████ | 5.61G/6.17G [00:18<00:01, 333MB/s]#015Downloading pytorch_model.bin:  92%|█████████▏| 5.65G/6.17G [00:18<00:01, 321MB/s]#015Downloading pytorch_model.bin:  92%|█████████▏| 5.69G/6.17G [00:18<00:01, 331MB/s]#015Downloading pytorch_model.bin:  93%|█████████▎| 5.74G/6.17G [00:18<00:01, 324MB/s]#015Downloading pytorch_model.bin:  94%|█████████▎| 5.78G/6.17G [00:18<00:01, 322MB/s]#015Downloading pytorch_model.bin:  94%|█████████▍| 5.82G/6.17G [00:18<00:01, 323MB/s]#015Downloading pytorch_model.bin:  95%|█████████▍| 5.86G/6.17G [00:18<00:00, 325MB/s]#015Downloading pytorch_model.bin:  96%|█████████▌| 5.90G/6.17G [00:18<00:00, 328MB/s]#015Downloading pytorch_model.bin:  96%|█████████▋| 5.95G/6.17G [00:19<00:00, 328MB/s]#015Downloading pytorch_model.bin:  97%|█████████▋| 5.99G/6.17G [00:19<00:00, 332MB/s]#015Downloading pytorch_model.bin:  98%|█████████▊| 6.03G/6.17G [00:19<00:00, 327MB/s]#015Downloading pytorch_model.bin:  98%|█████████▊| 6.07G/6.17G [00:19<00:00, 324MB/s]#015Downloading pytorch_model.bin:  99%|█████████▉| 6.11G/6.17G [00:19<00:00, 312MB/s]#015Downloading pytorch_model.bin: 100%|█████████▉| 6.16G/6.17G [00:19<00:00, 323MB/s]#015Downloading pytorch_model.bin: 100%|██████████| 6.17G/6.17G [00:19<00:00, 313MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)neration_config.json:   0%|          | 0.00/3.51k [00:00<?, ?B/s]#015Downloading (…)neration_config.json: 100%|██████████| 3.51k/3.51k [00:00<00:00, 21.2MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)okenizer_config.json:   0%|          | 0.00/800 [00:00<?, ?B/s]#015Downloading (…)okenizer_config.json: 100%|██████████| 800/800 [00:00<00:00, 5.89MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)olve/main/vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]#015Downloading (…)olve/main/vocab.json: 100%|██████████| 836k/836k [00:00<00:00, 71.6MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]#015Downloading (…)/main/tokenizer.json: 100%|██████████| 2.20M/2.20M [00:00<00:00, 79.7MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)olve/main/merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]#015Downloading (…)olve/main/merges.txt: 100%|██████████| 494k/494k [00:00<00:00, 3.39MB/s]#015Downloading (…)olve/main/merges.txt: 100%|██████████| 494k/494k [00:00<00:00, 3.38MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)main/normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]#015Downloading (…)main/normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 165MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]#015Downloading (…)in/added_tokens.json: 100%|██████████| 2.08k/2.08k [00:00<00:00, 17.6MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]#015Downloading (…)cial_tokens_map.json: 100%|██████████| 2.08k/2.08k [00:00<00:00, 18.0MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)rocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]#015Downloading (…)rocessor_config.json: 100%|██████████| 185k/185k [00:00<00:00, 16.8MB/s]\u001b[0m\n",
      "\u001b[34m/opt/ml/processing/input/genai_interview.mp4\u001b[0m\n",
      "\u001b[34mMoviePy - Writing audio in /opt/ml/processing/input/genai_interview.mp3\u001b[0m\n",
      "\u001b[34mMoviePy - Done.\u001b[0m\n",
      "\n",
      "\u001b[34m#015chunk:   0%|          | 0/23015 [00:00<?, ?it/s, now=None]#015chunk:   1%|          | 117/23015 [00:00<00:19, 1159.17it/s, now=None]#015chunk:   1%|          | 240/23015 [00:00<00:19, 1179.83it/s, now=None]#015chunk:   2%|▏         | 358/23015 [00:00<00:19, 1167.63it/s, now=None]#015chunk:   2%|▏         | 475/23015 [00:00<00:19, 1154.71it/s, now=None]#015chunk:   3%|▎         | 591/23015 [00:00<00:19, 1144.43it/s, now=None]#015chunk:   3%|▎         | 706/23015 [00:00<00:20, 1113.93it/s, now=None]#015chunk:   4%|▎         | 821/23015 [00:00<00:19, 1120.83it/s, now=None]#015chunk:   4%|▍         | 934/23015 [00:00<00:21, 1008.48it/s, now=None]#015chunk:   5%|▍         | 1037/23015 [00:00<00:23, 932.82it/s, now=None]#015chunk:   5%|▍         | 1133/23015 [00:01<00:23, 917.87it/s, now=None]#015chunk:   6%|▌         | 1293/23015 [00:01<00:19, 1103.79it/s, now=None]#015chunk:   6%|▋         | 1456/23015 [00:01<00:17, 1246.15it/s, now=None]#015chunk:   7%|▋         | 1614/23015 [00:01<00:15, 1341.11it/s, now=None]#015chunk:   8%|▊         | 1782/23015 [00:01<00:14, 1439.05it/s, now=None]#015chunk:   8%|▊         | 1937/23015 [00:01<00:14, 1468.69it/s, now=None]#015chunk:   9%|▉         | 2086/23015 [00:01<00:14, 1438.75it/s, now=None]#015chunk:  10%|▉         | 2232/23015 [00:01<00:15, 1342.94it/s, now=None]#015chunk:  10%|█         | 2369/23015 [00:01<00:15, 1290.51it/s, now=None]#015chunk:  11%|█         | 2500/23015 [00:02<00:16, 1237.66it/s, now=None]#015chunk:  11%|█▏        | 2625/23015 [00:02<00:16, 1203.07it/s, now=None]#015chunk:  12%|█▏        | 2747/23015 [00:02<00:17, 1186.67it/s, now=None]#015chunk:  12%|█▏        | 2867/23015 [00:02<00:17, 1166.41it/s, now=None]#015chunk:  13%|█▎        | 2984/23015 [00:02<00:17, 1158.53it/s, now=None]#015chunk:  13%|█▎        | 3101/23015 [00:02<00:17, 1160.79it/s, now=None]#015chunk:  14%|█▍        | 3218/23015 [00:02<00:17, 1116.11it/s, now=None]#015chunk:  14%|█▍        | 3330/23015 [00:02<00:18, 1078.37it/s, now=None]#015chunk:  15%|█▍        | 3439/23015 [00:02<00:18, 1080.01it/s, now=None]#015chunk:  15%|█▌        | 3548/23015 [00:03<00:18, 1079.88it/s, now=None]#015chunk:  16%|█▌        | 3657/23015 [00:03<00:18, 1068.92it/s, now=None]#015chunk:  16%|█▋        | 3767/23015 [00:03<00:18, 1063.77it/s, now=None]#015chunk:  17%|█▋        | 3879/23015 [00:03<00:17, 1076.77it/s, now=None]#015chunk:  17%|█▋        | 3988/23015 [00:03<00:17, 1076.93it/s, now=None]#015chunk:  18%|█▊        | 4096/23015 [00:03<00:17, 1076.77it/s, now=None]#015chunk:  18%|█▊        | 4204/23015 [00:03<00:17, 1069.90it/s, now=None]#015chunk:  19%|█▊        | 4312/23015 [00:03<00:17, 1072.38it/s, now=None]#015chunk:  19%|█▉        | 4420/23015 [00:03<00:17, 1067.50it/s, now=None]#015chunk:  20%|█▉        | 4537/23015 [00:03<00:16, 1097.60it/s, now=None]#015chunk:  20%|██        | 4652/23015 [00:04<00:16, 1109.65it/s, now=None]#015chunk:  21%|██        | 4769/23015 [00:04<00:16, 1122.13it/s, now=None]#015chunk:  21%|██        | 4882/23015 [00:04<00:16, 1118.14it/s, now=None]#015chunk:  22%|██▏       | 4994/23015 [00:04<00:16, 1106.42it/s, now=None]#015chunk:  22%|██▏       | 5105/23015 [00:04<00:16, 1099.48it/s, now=None]#015chunk:  23%|██▎       | 5215/23015 [00:04<00:16, 1098.52it/s, now=None]#015chunk:  23%|██▎       | 5325/23015 [00:04<00:16, 1085.56it/s, now=None]#015chunk:  24%|██▎       | 5434/23015 [00:04<00:16, 1067.02it/s, now=None]#015chunk:  24%|██▍       | 5541/23015 [00:04<00:16, 1058.31it/s, now=None]#015chunk:  25%|██▍       | 5651/23015 [00:04<00:16, 1063.94it/s, now=None]#015chunk:  25%|██▌       | 5758/23015 [00:05<00:16, 1042.40it/s, now=None]#015chunk:  25%|██▌       | 5868/23015 [00:05<00:16, 1055.64it/s, now=None]#015chunk:  26%|██▌       | 5975/23015 [00:05<00:16, 1054.70it/s, now=None]#015chunk:  26%|██▋       | 6091/23015 [00:05<00:15, 1080.22it/s, now=None]#015chunk:  27%|██▋       | 6203/23015 [00:05<00:15, 1089.26it/s, now=None]#015chunk:  27%|██▋       | 6319/23015 [00:05<00:15, 1107.89it/s, now=None]#015chunk:  28%|██▊       | 6430/23015 [00:05<00:15, 1092.74it/s, now=None]#015chunk:  28%|██▊       | 6540/23015 [00:05<00:15, 1066.22it/s, now=None]#015chunk:  29%|██▉       | 6647/23015 [00:05<00:16, 1006.55it/s, now=None]#015chunk:  29%|██▉       | 6749/23015 [00:06<00:16, 967.45it/s, now=None] #015chunk:  30%|██▉       | 6855/23015 [00:06<00:16, 988.10it/s, now=None]#015chunk:  30%|███       | 6965/23015 [00:06<00:15, 1012.75it/s, now=None]#015chunk:  31%|███       | 7080/23015 [00:06<00:15, 1043.48it/s, now=None]#015chunk:  31%|███       | 7192/23015 [00:06<00:14, 1061.76it/s, now=None]#015chunk:  32%|███▏      | 7305/23015 [00:06<00:14, 1081.21it/s, now=None]#015chunk:  32%|███▏      | 7414/23015 [00:06<00:14, 1051.62it/s, now=None]#015chunk:  33%|███▎      | 7520/23015 [00:06<00:14, 1039.01it/s, now=None]#015chunk:  33%|███▎      | 7625/23015 [00:06<00:14, 1033.51it/s, now=None]#015chunk:  34%|███▎      | 7733/23015 [00:06<00:14, 1045.25it/s, now=None]#015chunk:  34%|███▍      | 7843/23015 [00:07<00:14, 1061.11it/s, now=None]#015chunk:  35%|███▍      | 7955/23015 [00:07<00:14, 1067.48it/s, now=None]#015chunk:  35%|███▌      | 8085/23015 [00:07<00:13, 1135.87it/s, now=None]#015chunk:  36%|███▌      | 8217/23015 [00:07<00:12, 1186.26it/s, now=None]#015chunk:  36%|███▋      | 8351/23015 [00:07<00:11, 1231.24it/s, now=None]#015chunk:  37%|███▋      | 8476/23015 [00:07<00:11, 1228.05it/s, now=None]#015chunk:  37%|███▋      | 8604/23015 [00:07<00:11, 1236.20it/s, now=None]#015chunk:  38%|███▊      | 8735/23015 [00:07<00:11, 1257.98it/s, now=None]#015chunk:  39%|███▊      | 8862/23015 [00:07<00:11, 1252.27it/s, now=None]#015chunk:  39%|███▉      | 8988/23015 [00:07<00:11, 1248.12it/s, now=None]#015chunk:  40%|███▉      | 9122/23015 [00:08<00:10, 1271.40it/s, now=None]#015chunk:  40%|████      | 9250/23015 [00:08<00:10, 1267.61it/s, now=None]#015chunk:  41%|████      | 9377/23015 [00:08<00:10, 1258.52it/s, now=None]#015chunk:  41%|████▏     | 9507/23015 [00:08<00:10, 1267.38it/s, now=None]#015chunk:  42%|████▏     | 9634/23015 [00:08<00:10, 1263.16it/s, now=None]#015chunk:  42%|████▏     | 9762/23015 [00:08<00:10, 1267.27it/s, now=None]#015chunk:  43%|████▎     | 9889/23015 [00:08<00:10, 1253.31it/s, now=None]#015chunk:  44%|████▎     | 10015/23015 [00:08<00:10, 1213.36it/s, now=None]#015chunk:  44%|████▍     | 10137/23015 [00:08<00:11, 1131.62it/s, now=None]#015chunk:  45%|████▍     | 10252/23015 [00:09<00:11, 1086.82it/s, now=None]#015chunk:  45%|████▌     | 10362/23015 [00:09<00:11, 1082.01it/s, now=None]#015chunk:  45%|████▌     | 10471/23015 [00:09<00:11, 1048.30it/s, now=None]#015chunk:  46%|████▌     | 10577/23015 [00:09<00:11, 1045.74it/s, now=None]#015chunk:  46%|████▋     | 10683/23015 [00:09<00:11, 1039.14it/s, now=None]#015chunk:  47%|████▋     | 10789/23015 [00:09<00:11, 1041.00it/s, now=None]#015chunk:  47%|████▋     | 10896/23015 [00:09<00:11, 1037.52it/s, now=None]#015chunk:  48%|████▊     | 11007/23015 [00:09<00:11, 1058.06it/s, now=None]#015chunk:  48%|████▊     | 11113/23015 [00:09<00:11, 1051.65it/s, now=None]#015chunk:  49%|████▊     | 11219/23015 [00:09<00:11, 1044.75it/s, now=None]#015chunk:  49%|████▉     | 11324/23015 [00:10<00:11, 1032.82it/s, now=None]#015chunk:  50%|████▉     | 11428/23015 [00:10<00:11, 1021.10it/s, now=None]#015chunk:  50%|█████     | 11541/23015 [00:10<00:10, 1052.32it/s, now=None]#015chunk:  51%|█████     | 11649/23015 [00:10<00:10, 1056.08it/s, now=None]#015chunk:  51%|█████     | 11759/23015 [00:10<00:10, 1056.93it/s, now=None]#015chunk:  52%|█████▏    | 11866/23015 [00:10<00:10, 1053.88it/s, now=None]#015chunk:  52%|█████▏    | 11980/23015 [00:10<00:10, 1078.11it/s, now=None]#015chunk:  53%|█████▎    | 12095/23015 [00:10<00:10, 1091.09it/s, now=None]#015chunk:  53%|█████▎    | 12205/23015 [00:10<00:09, 1086.01it/s, now=None]#015chunk:  54%|█████▎    | 12314/23015 [00:10<00:09, 1077.41it/s, now=None]#015chunk:  54%|█████▍    | 12423/23015 [00:11<00:09, 1074.79it/s, now=None]#015chunk:  54%|█████▍    | 12531/23015 [00:11<00:09, 1053.12it/s, now=None]#015chunk:  55%|█████▍    | 12637/23015 [00:11<00:10, 1033.58it/s, now=None]#015chunk:  55%|█████▌    | 12742/23015 [00:11<00:09, 1030.17it/s, now=None]#015chunk:  56%|█████▌    | 12852/23015 [00:11<00:09, 1050.41it/s, now=None]#015chunk:  56%|█████▋    | 12958/23015 [00:11<00:09, 1019.64it/s, now=None]#015chunk:  57%|█████▋    | 13061/23015 [00:11<00:09, 1001.61it/s, now=None]#015chunk:  57%|█████▋    | 13164/23015 [00:11<00:09, 1002.61it/s, now=None]#015chunk:  58%|█████▊    | 13266/23015 [00:11<00:09, 1002.68it/s, now=None]#015chunk:  58%|█████▊    | 13369/23015 [00:12<00:09, 1007.01it/s, now=None]#015chunk:  59%|█████▊    | 13475/23015 [00:12<00:09, 1018.45it/s, now=None]#015chunk:  59%|█████▉    | 13622/23015 [00:12<00:08, 1151.12it/s, now=None]#015chunk:  60%|█████▉    | 13785/23015 [00:12<00:07, 1289.24it/s, now=None]#015chunk:  61%|██████    | 13946/23015 [00:12<00:06, 1379.04it/s, now=None]#015chunk:  61%|██████▏   | 14105/23015 [00:12<00:06, 1436.53it/s, now=None]#015chunk:  62%|██████▏   | 14263/23015 [00:12<00:05, 1478.71it/s, now=None]#015chunk:  63%|██████▎   | 14412/23015 [00:12<00:05, 1436.46it/s, now=None]#015chunk:  63%|██████▎   | 14557/23015 [00:12<00:06, 1371.84it/s, now=None]#015chunk:  64%|██████▍   | 14695/23015 [00:12<00:06, 1300.17it/s, now=None]#015chunk:  64%|██████▍   | 14827/23015 [00:13<00:06, 1253.71it/s, now=None]#015chunk:  65%|██████▍   | 14954/23015 [00:13<00:06, 1232.38it/s, now=None]#015chunk:  66%|██████▌   | 15078/23015 [00:13<00:06, 1187.65it/s, now=None]#015chunk:  66%|██████▌   | 15198/23015 [00:13<00:06, 1163.09it/s, now=None]#015chunk:  67%|██████▋   | 15315/23015 [00:13<00:06, 1124.38it/s, now=None]#015chunk:  67%|██████▋   | 15428/23015 [00:13<00:06, 1124.65it/s, now=None]#015chunk:  68%|██████▊   | 15541/23015 [00:13<00:06, 1114.97it/s, now=None]#015chunk:  68%|██████▊   | 15653/23015 [00:13<00:06, 1115.98it/s, now=None]#015chunk:  68%|██████▊   | 15765/23015 [00:13<00:06, 1096.21it/s, now=None]#015chunk:  69%|██████▉   | 15883/23015 [00:14<00:06, 1120.41it/s, now=None]#015chunk:  70%|██████▉   | 15996/23015 [00:14<00:06, 1104.24it/s, now=None]#015chunk:  70%|██████▉   | 16109/23015 [00:14<00:06, 1103.41it/s, now=None]#015chunk:  70%|███████   | 16220/23015 [00:14<00:06, 1081.80it/s, now=None]#015chunk:  71%|███████   | 16329/23015 [00:14<00:06, 1083.63it/s, now=None]#015chunk:  71%|███████▏  | 16438/23015 [00:14<00:06, 1080.32it/s, now=None]#015chunk:  72%|███████▏  | 16585/23015 [00:14<00:05, 1194.71it/s, now=None]#015chunk:  73%|███████▎  | 16713/23015 [00:14<00:05, 1217.74it/s, now=None]#015chunk:  73%|███████▎  | 16840/23015 [00:14<00:05, 1232.86it/s, now=None]#015chunk:  74%|███████▎  | 16967/23015 [00:14<00:04, 1239.82it/s, now=None]#015chunk:  74%|███████▍  | 17112/23015 [00:15<00:04, 1293.72it/s, now=None]#015chunk:  75%|███████▍  | 17250/23015 [00:15<00:04, 1311.46it/s, now=None]#015chunk:  76%|███████▌  | 17382/23015 [00:24<01:59, 47.26it/s, now=None]  #015chunk:  76%|███████▌  | 17495/23015 [00:24<01:26, 63.51it/s, now=None]#015chunk:  76%|███████▋  | 17596/23015 [00:24<01:05, 83.37it/s, now=None]#015chunk:  77%|███████▋  | 17700/23015 [00:24<00:47, 111.12it/s, now=None]#015chunk:  77%|███████▋  | 17819/23015 [00:24<00:33, 154.03it/s, now=None]#015chunk:  78%|███████▊  | 17934/23015 [00:24<00:24, 207.64it/s, now=None]#015chunk:  78%|███████▊  | 18052/23015 [00:24<00:17, 276.96it/s, now=None]#015chunk:  79%|███████▉  | 18163/23015 [00:25<00:13, 352.06it/s, now=None]#015chunk:  79%|███████▉  | 18273/23015 [00:25<00:10, 438.54it/s, now=None]#015chunk:  80%|███████▉  | 18384/23015 [00:25<00:08, 532.26it/s, now=None]#015chunk:  80%|████████  | 18493/23015 [00:25<00:07, 624.42it/s, now=None]#015chunk:  81%|████████  | 18602/23015 [00:25<00:06, 705.09it/s, now=None]#015chunk:  81%|████████▏ | 18716/23015 [00:25<00:05, 795.19it/s, now=None]#015chunk:  82%|████████▏ | 18825/23015 [00:25<00:04, 853.36it/s, now=None]#015chunk:  82%|████████▏ | 18937/23015 [00:25<00:04, 913.01it/s, now=None]#015chunk:  83%|████████▎ | 19045/23015 [00:25<00:04, 944.43it/s, now=None]#015chunk:  83%|████████▎ | 19155/23015 [00:25<00:03, 985.81it/s, now=None]#015chunk:  84%|████████▎ | 19268/23015 [00:26<00:03, 1025.77it/s, now=None]#015chunk:  84%|████████▍ | 19379/23015 [00:26<00:03, 1036.09it/s, now=None]#015chunk:  85%|████████▍ | 19494/23015 [00:26<00:03, 1065.20it/s, now=None]#015chunk:  85%|████████▌ | 19617/23015 [00:26<00:03, 1104.82it/s, now=None]#015chunk:  86%|████████▌ | 19740/23015 [00:26<00:02, 1136.10it/s, now=None]#015chunk:  86%|████████▋ | 19856/23015 [00:26<00:02, 1139.08it/s, now=None]#015chunk:  87%|████████▋ | 19972/23015 [00:26<00:02, 1135.45it/s, now=None]#015chunk:  87%|████████▋ | 20087/23015 [00:26<00:02, 1130.41it/s, now=None]#015chunk:  88%|████████▊ | 20201/23015 [00:26<00:02, 1131.97it/s, now=None]#015chunk:  88%|████████▊ | 20315/23015 [00:26<00:02, 1128.73it/s, now=None]#015chunk:  89%|████████▉ | 20429/23015 [00:27<00:02, 1128.69it/s, now=None]#015chunk:  89%|████████▉ | 20547/23015 [00:27<00:02, 1139.04it/s, now=None]#015chunk:  90%|████████▉ | 20662/23015 [00:27<00:02, 1135.31it/s, now=None]#015chunk:  90%|█████████ | 20780/23015 [00:27<00:01, 1141.96it/s, now=None]#015chunk:  91%|█████████ | 20895/23015 [00:27<00:01, 1123.73it/s, now=None]#015chunk:  91%|█████████▏| 21013/23015 [00:27<00:01, 1138.42it/s, now=None]#015chunk:  92%|█████████▏| 21128/23015 [00:27<00:01, 1134.27it/s, now=None]#015chunk:  92%|█████████▏| 21242/23015 [00:27<00:01, 1118.09it/s, now=None]#015chunk:  93%|█████████▎| 21354/23015 [00:27<00:01, 1094.79it/s, now=None]#015chunk:  93%|█████████▎| 21465/23015 [00:28<00:01, 1097.94it/s, now=None]#015chunk:  94%|█████████▎| 21575/23015 [00:28<00:01, 1086.87it/s, now=None]#015chunk:  94%|█████████▍| 21685/23015 [00:28<00:01, 1086.86it/s, now=None]#015chunk:  95%|█████████▍| 21794/23015 [00:28<00:01, 1074.82it/s, now=None]#015chunk:  95%|█████████▌| 21910/23015 [00:28<00:01, 1098.07it/s, now=None]#015chunk:  96%|█████████▌| 22028/23015 [00:28<00:00, 1122.08it/s, now=None]#015chunk:  96%|█████████▌| 22141/23015 [00:28<00:00, 1112.73it/s, now=None]#015chunk:  97%|█████████▋| 22253/23015 [00:28<00:00, 1063.59it/s, now=None]#015chunk:  97%|█████████▋| 22405/23015 [00:28<00:00, 1189.55it/s, now=None]#015chunk:  98%|█████████▊| 22570/23015 [00:28<00:00, 1320.47it/s, now=None]#015chunk:  99%|█████████▉| 22734/23015 [00:29<00:00, 1413.45it/s, now=None]#015chunk:  99%|█████████▉| 22892/23015 [00:29<00:00, 1462.14it/s, now=None]#015                                                                        #015#015Downloading (…)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]#015Downloading (…)a8e1d/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 9.35MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]#015Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.79MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]#015Downloading (…)b20bca8e1d/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 67.1MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]#015Downloading (…)0bca8e1d/config.json: 100%|██████████| 571/571 [00:00<00:00, 5.02MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]#015Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 1.14MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]#015Downloading (…)e1d/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 149MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]#015Downloading pytorch_model.bin:   2%|▏         | 10.5M/438M [00:00<00:04, 94.0MB/s]#015Downloading pytorch_model.bin:   7%|▋         | 31.5M/438M [00:00<00:02, 148MB/s] #015Downloading pytorch_model.bin:  14%|█▍        | 62.9M/438M [00:00<00:01, 217MB/s]#015Downloading pytorch_model.bin:  22%|██▏       | 94.4M/438M [00:00<00:01, 249MB/s]#015Downloading pytorch_model.bin:  31%|███       | 136M/438M [00:00<00:01, 282MB/s] #015Downloading pytorch_model.bin:  38%|███▊      | 168M/438M [00:00<00:00, 285MB/s]#015Downloading pytorch_model.bin:  48%|████▊     | 210M/438M [00:00<00:00, 306MB/s]#015Downloading pytorch_model.bin:  55%|█████▌    | 241M/438M [00:00<00:00, 304MB/s]#015Downloading pytorch_model.bin:  65%|██████▍   | 283M/438M [00:01<00:00, 307MB/s]#015Downloading pytorch_model.bin:  74%|███████▍  | 325M/438M [00:01<00:00, 312MB/s]#015Downloading pytorch_model.bin:  84%|████████▍ | 367M/438M [00:01<00:00, 316MB/s]#015Downloading pytorch_model.bin:  93%|█████████▎| 409M/438M [00:01<00:00, 315MB/s]#015Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:01<00:00, 289MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]#015Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 464kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]#015Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 1.89MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading (…)a8e1d/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 54.1MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]#015Downloading (…)okenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 2.88MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]#015Downloading (…)8e1d/train_script.py: 100%|██████████| 13.1k/13.1k [00:00<00:00, 67.9MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading (…)b20bca8e1d/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]#015Downloading (…)bca8e1d/modules.json: 100%|██████████| 349/349 [00:00<00:00, 2.74MB/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hfp.run(\n",
    "    code='preprocessing.py',\n",
    "    source_dir=\"data_preparation\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=s3_input, destination=\"/opt/ml/processing/input\")\n",
    "    ], \n",
    "    outputs=[\n",
    "        ProcessingOutput(source='/opt/ml/processing/output_clips', destination=s3_output_clips),\n",
    "        ProcessingOutput(source='/opt/ml/processing/transcripts', destination=s3_output_transcript),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--whisper-model\", \"whisper-large-v2\",\n",
    "        \"--target-language\", \"en\",\n",
    "        \"--sentence-embedding-model\", \"all-mpnet-base-v2\",\n",
    "        \"--order\", \"5\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efea032-76d4-478c-943a-a4be59d47ea7",
   "metadata": {},
   "source": [
    "## Deploy Whipser model to SageMaker for real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed73b43-b5c7-4e1a-bd15-8e020cab8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name=\"whisper-large-v2\"\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'openai/whisper-large-v2',\n",
    "    'HF_TASK':'automatic-speech-recognition',\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.26.0',\n",
    "    pytorch_version='1.13.1',\n",
    "    py_version='py39',\n",
    "    \n",
    "    env=hub,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00b59f-c17c-4446-a900-55e2835c5625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1, # number of instances\n",
    "    instance_type='ml.g5.xlarge' # ec2 instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3d59a-0ccf-4baf-95d9-a292c43872dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('runtime.sagemaker')\n",
    "file = \"test.webm\"\n",
    "with open(file, \"rb\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8d3ec-15a3-4e5f-b85b-19dd5ce98dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='audio/x-audio', Body=data)\n",
    "output = json.loads(response['Body'].read())\n",
    "print(f\"Extracted text from the audio file:\\n {output['text']}\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
