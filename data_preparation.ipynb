{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd8d0c0-2c2d-4751-8f5d-999d79ae6108",
   "metadata": {},
   "source": [
    "## Text Extraction with Whisper\n",
    "\n",
    "In this notebook, we will extract information from video/audio files with [Whipser model](https://github.com/openai/whisper). Be leveraging multilingual support, we can extract tanscripts from videos files mixed different languages, even for one video file with different languanges. We provide the following options for whisper inference:\n",
    "- Batch inference with SageMaker Processing job, we can process massive data and store them into vector database for RAG solution.\n",
    "- Real-time inference with SageMaker Endpoint, we can leverage it to do summarizaton or QA with a short video/audio file (less than 6MB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a02764-403f-4c35-9754-e99e2a8d5b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38922488-e64f-45e2-983a-5c176f4e13ab",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c209ddd-7a9a-4c7c-b582-6729ce88a4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceProcessor\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"sagemaker/rag_video\"\n",
    "s3_input = f\"s3://{bucket}/{prefix}/raw_data\" # Directory for video files\n",
    "s3_output_clips = f\"s3://{bucket}/{prefix}/clips\" # Directory for video clips\n",
    "s3_output_transcript = f\"s3://{bucket}/{prefix}/transcript\" # Directory for transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb4961b-513c-405c-a847-b549b9b854d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 's3_output_transcript' (str)\n",
      "Stored 's3_output_clips' (str)\n"
     ]
    }
   ],
   "source": [
    "%store s3_output_transcript\n",
    "%store s3_output_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892e7ff-edfe-4112-9ccd-bc34b2fc1bde",
   "metadata": {},
   "source": [
    "## Upload test data to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02daea10-0cbf-4f5d-b294-023f6d56b12f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./test_video.mp4 to s3://sagemaker-us-east-1-822507008821/sagemaker/rag_video/raw_data/test_video.mp4\n",
      "upload: ./test_audio.mp3 to s3://sagemaker-us-east-1-822507008821/sagemaker/rag_video/raw_data/test_audio.mp3\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp test_video.mp4 {s3_input}/\n",
    "!aws s3 cp test_audio.mp3 {s3_input}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00c2e3-c897-4a2c-a12e-b07c75ca5986",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch inference with SageMaker Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e002118-b7dc-4915-9fe0-f80e3bbfe847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hfp = HuggingFaceProcessor(\n",
    "    role=get_execution_role(), \n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    transformers_version='4.28.1',\n",
    "    pytorch_version='2.0.0', \n",
    "    base_job_name='frameworkprocessor-hf',\n",
    "    py_version=\"py310\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90383250-179b-4499-8583-fdca5320ee75",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded data_preparation to s3://sagemaker-us-east-1-822507008821/frameworkprocessor-hf-2023-07-12-16-44-37-718/source/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-822507008821/frameworkprocessor-hf-2023-07-12-16-44-37-718/source/runproc.sh\n",
      "INFO:sagemaker:Creating processing-job with name frameworkprocessor-hf-2023-07-12-16-44-37-718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "..........................................................\u001b[34mWARNING: Skipping typing as it is not installed.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting git+https://github.com/openai/whisper.git (from -r requirements.txt (line 3))\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-bap8p6al\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-bap8p6al\n",
      "  Resolved https://github.com/openai/whisper.git to commit b91c907694f96a3fb9da03d4bbdc83fbcd3a40a4\n",
      "  Installing build dependencies: started\u001b[0m\n",
      "\u001b[34m  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from -r requirements.txt (line 1))\n",
      "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 45.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting moviepy (from -r requirements.txt (line 2))\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 388.3/388.3 kB 42.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.154.0)\u001b[0m\n",
      "\u001b[34mCollecting pydub (from -r requirements.txt (line 5))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mCollecting sentence-transformers (from -r requirements.txt (line 6))\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 15.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting decorator<5.0,>=4.0.2 (from moviepy->-r requirements.txt (line 2))\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy->-r requirements.txt (line 2)) (4.65.0)\u001b[0m\n",
      "\u001b[34mCollecting proglog<=1.0.0 (from moviepy->-r requirements.txt (line 2))\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy->-r requirements.txt (line 2)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy->-r requirements.txt (line 2)) (2.28.1)\u001b[0m\n",
      "\u001b[34mCollecting imageio_ffmpeg>=0.2.0 (from moviepy->-r requirements.txt (line 2))\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.9/26.9 MB 50.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting triton==2.0.0 (from openai-whisper==20230314->-r requirements.txt (line 3))\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.3/63.3 MB 26.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314->-r requirements.txt (line 3)) (0.56.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314->-r requirements.txt (line 3)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting more-itertools (from openai-whisper==20230314->-r requirements.txt (line 3))\n",
      "  Downloading more_itertools-9.1.0-py3-none-any.whl (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 9.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from -r requirements.txt (line 1))\n",
      "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 66.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314->-r requirements.txt (line 3)) (3.26.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314->-r requirements.txt (line 3)) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314->-r requirements.txt (line 3)) (16.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3<2.0,>=1.26.28 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (1.26.132)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (3.20.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (4.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML==5.4.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (4.17.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 4)) (1.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (0.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (1.10.1)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from sentence-transformers->-r requirements.txt (line 6))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 69.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (0.1.99)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 6)) (0.14.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.30.0,>=1.29.132 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 4)) (1.29.132)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 4)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 6)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 6)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy->-r requirements.txt (line 2)) (9.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker->-r requirements.txt (line 4)) (3.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 3)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 3)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 3)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->-r requirements.txt (line 6)) (0.13.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 4)) (0.19.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers->-r requirements.txt (line 6)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers->-r requirements.txt (line 6)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20230314->-r requirements.txt (line 3)) (0.39.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20230314->-r requirements.txt (line 3)) (65.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker->-r requirements.txt (line 4)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker->-r requirements.txt (line 4)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker->-r requirements.txt (line 4)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 4)) (1.7.6.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 4)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 4)) (0.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 4)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker->-r requirements.txt (line 4)) (21.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 6)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20230314->-r requirements.txt (line 3)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20230314->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: moviepy, openai-whisper, sentence-transformers\n",
      "  Building wheel for moviepy (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for moviepy (setup.py): finished with status 'done'\n",
      "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110730 sha256=2d75d5ea53556c7335e760e7d94085fb5aa74c44166e5ab3f1476c7f3e9dd1bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798285 sha256=96521c7e058593165df130f40aa14f688c133dbd38e556528dc5575457c38f0a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2yptw42s/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "  Building wheel for sentence-transformers (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=10d9fa793c47cf6d34fa32902d73700e48beece09611ed0aa4f555ce7261f58e\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\u001b[0m\n",
      "\u001b[34mSuccessfully built moviepy openai-whisper sentence-transformers\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pydub, proglog, nltk, more-itertools, imageio_ffmpeg, decorator, tiktoken, moviepy, triton, sentence-transformers, openai-whisper\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled decorator-5.1.1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0.dev20221202\n",
      "    Uninstalling triton-2.0.0.dev20221202:\n",
      "      Successfully uninstalled triton-2.0.0.dev20221202\u001b[0m\n",
      "\u001b[34mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.8 more-itertools-9.1.0 moviepy-1.0.3 nltk-3.8.1 openai-whisper-20230314 proglog-0.1.10 pydub-0.25.1 sentence-transformers-2.2.2 tiktoken-0.3.3 triton-2.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m#015Downloading (…)lve/main/config.json:   0%|          | 0.00/1.99k [00:00<?, ?B/s]#015Downloading (…)lve/main/config.json: 100%|██████████| 1.99k/1.99k [00:00<00:00, 14.7MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading pytorch_model.bin:   0%|          | 0.00/6.17G [00:00<?, ?B/s]#015Downloading pytorch_model.bin:   1%|          | 31.5M/6.17G [00:00<00:26, 231MB/s]#015Downloading pytorch_model.bin:   1%|          | 62.9M/6.17G [00:00<00:23, 264MB/s]#015Downloading pytorch_model.bin:   2%|▏         | 94.4M/6.17G [00:00<00:24, 251MB/s]#015Downloading pytorch_model.bin:   2%|▏         | 126M/6.17G [00:00<00:22, 266MB/s] #015Downloading pytorch_model.bin:   3%|▎         | 157M/6.17G [00:00<00:21, 277MB/s]#015Downloading pytorch_model.bin:   3%|▎         | 189M/6.17G [00:00<00:23, 258MB/s]#015Downloading pytorch_model.bin:   4%|▎         | 220M/6.17G [00:00<00:22, 259MB/s]#015Downloading pytorch_model.bin:   4%|▍         | 252M/6.17G [00:00<00:22, 264MB/s]#015Downloading pytorch_model.bin:   5%|▍         | 283M/6.17G [00:01<00:23, 255MB/s]#015Downloading pytorch_model.bin:   5%|▌         | 315M/6.17G [00:01<00:22, 258MB/s]#015Downloading pytorch_model.bin:   6%|▌         | 346M/6.17G [00:01<00:22, 260MB/s]#015Downloading pytorch_model.bin:   6%|▌         | 377M/6.17G [00:01<00:21, 267MB/s]#015Downloading pytorch_model.bin:   7%|▋         | 409M/6.17G [00:01<00:21, 269MB/s]#015Downloading pytorch_model.bin:   7%|▋         | 440M/6.17G [00:01<00:20, 281MB/s]#015Downloading pytorch_model.bin:   8%|▊         | 472M/6.17G [00:01<00:20, 279MB/s]#015Downloading pytorch_model.bin:   8%|▊         | 503M/6.17G [00:01<00:20, 278MB/s]#015Downloading pytorch_model.bin:   9%|▊         | 535M/6.17G [00:02<00:21, 261MB/s]#015Downloading pytorch_model.bin:   9%|▉         | 566M/6.17G [00:02<00:21, 265MB/s]#015Downloading pytorch_model.bin:  10%|▉         | 598M/6.17G [00:02<00:22, 246MB/s]#015Downloading pytorch_model.bin:  10%|█         | 629M/6.17G [00:02<00:21, 255MB/s]#015Downloading pytorch_model.bin:  11%|█         | 661M/6.17G [00:02<00:21, 254MB/s]#015Downloading pytorch_model.bin:  11%|█         | 692M/6.17G [00:02<00:21, 257MB/s]#015Downloading pytorch_model.bin:  12%|█▏        | 724M/6.17G [00:02<00:21, 257MB/s]#015Downloading pytorch_model.bin:  12%|█▏        | 755M/6.17G [00:02<00:20, 268MB/s]#015Downloading pytorch_model.bin:  13%|█▎        | 786M/6.17G [00:02<00:19, 275MB/s]#015Downloading pytorch_model.bin:  13%|█▎        | 818M/6.17G [00:03<00:19, 281MB/s]#015Downloading pytorch_model.bin:  14%|█▍        | 860M/6.17G [00:03<00:18, 294MB/s]#015Downloading pytorch_model.bin:  14%|█▍        | 891M/6.17G [00:03<00:18, 284MB/s]#015Downloading pytorch_model.bin:  15%|█▍        | 923M/6.17G [00:03<00:18, 281MB/s]#015Downloading pytorch_model.bin:  15%|█▌        | 954M/6.17G [00:03<00:18, 281MB/s]#015Downloading pytorch_model.bin:  16%|█▌        | 986M/6.17G [00:03<00:19, 263MB/s]#015Downloading pytorch_model.bin:  17%|█▋        | 1.03G/6.17G [00:03<00:18, 280MB/s]#015Downloading pytorch_model.bin:  17%|█▋        | 1.06G/6.17G [00:03<00:17, 285MB/s]#015Downloading pytorch_model.bin:  18%|█▊        | 1.09G/6.17G [00:04<00:18, 274MB/s]#015Downloading pytorch_model.bin:  18%|█▊        | 1.12G/6.17G [00:04<00:19, 255MB/s]#015Downloading pytorch_model.bin:  19%|█▊        | 1.15G/6.17G [00:04<00:19, 252MB/s]#015Downloading pytorch_model.bin:  19%|█▉        | 1.18G/6.17G [00:04<00:20, 249MB/s]#015Downloading pytorch_model.bin:  20%|█▉        | 1.22G/6.17G [00:04<00:20, 246MB/s]#015Downloading pytorch_model.bin:  20%|██        | 1.25G/6.17G [00:04<00:19, 257MB/s]#015Downloading pytorch_model.bin:  21%|██        | 1.28G/6.17G [00:04<00:18, 264MB/s]#015Downloading pytorch_model.bin:  21%|██        | 1.31G/6.17G [00:04<00:19, 256MB/s]#015Downloading pytorch_model.bin:  22%|██▏       | 1.34G/6.17G [00:05<00:19, 252MB/s]#015Downloading pytorch_model.bin:  22%|██▏       | 1.37G/6.17G [00:05<00:18, 261MB/s]#015Downloading pytorch_model.bin:  23%|██▎       | 1.41G/6.17G [00:05<00:19, 250MB/s]#015Downloading pytorch_model.bin:  23%|██▎       | 1.44G/6.17G [00:05<00:18, 250MB/s]#015Downloading pytorch_model.bin:  24%|██▍       | 1.47G/6.17G [00:05<00:18, 255MB/s]#015Downloading pytorch_model.bin:  24%|██▍       | 1.50G/6.17G [00:05<00:18, 259MB/s]#015Downloading pytorch_model.bin:  25%|██▍       | 1.54G/6.17G [00:05<00:17, 268MB/s]#015Downloading pytorch_model.bin:  25%|██▌       | 1.57G/6.17G [00:05<00:17, 266MB/s]#015Downloading pytorch_model.bin:  26%|██▌       | 1.60G/6.17G [00:06<00:17, 264MB/s]#015Downloading pytorch_model.bin:  26%|██▋       | 1.64G/6.17G [00:06<00:17, 262MB/s]#015Downloading pytorch_model.bin:  27%|██▋       | 1.67G/6.17G [00:06<00:16, 274MB/s]#015Downloading pytorch_model.bin:  28%|██▊       | 1.70G/6.17G [00:06<00:15, 280MB/s]#015Downloading pytorch_model.bin:  28%|██▊       | 1.73G/6.17G [00:06<00:15, 281MB/s]#015Downloading pytorch_model.bin:  29%|██▊       | 1.76G/6.17G [00:06<00:17, 259MB/s]#015Downloading pytorch_model.bin:  29%|██▉       | 1.79G/6.17G [00:06<00:16, 265MB/s]#015Downloading pytorch_model.bin:  30%|██▉       | 1.82G/6.17G [00:06<00:17, 256MB/s]#015Downloading pytorch_model.bin:  30%|███       | 1.86G/6.17G [00:07<00:17, 251MB/s]#015Downloading pytorch_model.bin:  31%|███       | 1.89G/6.17G [00:07<00:17, 245MB/s]#015Downloading pytorch_model.bin:  31%|███       | 1.92G/6.17G [00:07<00:17, 238MB/s]#015Downloading pytorch_model.bin:  32%|███▏      | 1.95G/6.17G [00:07<00:16, 252MB/s]#015Downloading pytorch_model.bin:  32%|███▏      | 1.98G/6.17G [00:07<00:15, 266MB/s]#015Downloading pytorch_model.bin:  33%|███▎      | 2.01G/6.17G [00:07<00:16, 259MB/s]#015Downloading pytorch_model.bin:  33%|███▎      | 2.04G/6.17G [00:07<00:16, 251MB/s]#015Downloading pytorch_model.bin:  34%|███▎      | 2.08G/6.17G [00:07<00:15, 262MB/s]#015Downloading pytorch_model.bin:  34%|███▍      | 2.11G/6.17G [00:08<00:15, 260MB/s]#015Downloading pytorch_model.bin:  35%|███▍      | 2.14G/6.17G [00:08<00:15, 255MB/s]#015Downloading pytorch_model.bin:  35%|███▌      | 2.17G/6.17G [00:08<00:15, 251MB/s]#015Downloading pytorch_model.bin:  36%|███▌      | 2.20G/6.17G [00:08<00:15, 262MB/s]#015Downloading pytorch_model.bin:  36%|███▌      | 2.23G/6.17G [00:08<00:15, 261MB/s]#015Downloading pytorch_model.bin:  37%|███▋      | 2.26G/6.17G [00:08<00:14, 266MB/s]#015Downloading pytorch_model.bin:  37%|███▋      | 2.30G/6.17G [00:08<00:15, 255MB/s]#015Downloading pytorch_model.bin:  38%|███▊      | 2.33G/6.17G [00:08<00:14, 260MB/s]#015Downloading pytorch_model.bin:  38%|███▊      | 2.36G/6.17G [00:08<00:14, 258MB/s]#015Downloading pytorch_model.bin:  39%|███▊      | 2.39G/6.17G [00:09<00:14, 261MB/s]#015Downloading pytorch_model.bin:  39%|███▉      | 2.42G/6.17G [00:09<00:13, 273MB/s]#015Downloading pytorch_model.bin:  40%|███▉      | 2.45G/6.17G [00:09<00:14, 254MB/s]#015Downloading pytorch_model.bin:  40%|████      | 2.49G/6.17G [00:09<00:14, 246MB/s]#015Downloading pytorch_model.bin:  41%|████      | 2.52G/6.17G [00:09<00:13, 262MB/s]#015Downloading pytorch_model.bin:  41%|████▏     | 2.55G/6.17G [00:09<00:13, 271MB/s]#015Downloading pytorch_model.bin:  42%|████▏     | 2.58G/6.17G [00:09<00:13, 271MB/s]#015Downloading pytorch_model.bin:  42%|████▏     | 2.61G/6.17G [00:09<00:13, 269MB/s]#015Downloading pytorch_model.bin:  43%|████▎     | 2.64G/6.17G [00:10<00:12, 277MB/s]#015Downloading pytorch_model.bin:  43%|████▎     | 2.67G/6.17G [00:10<00:12, 280MB/s]#015Downloading pytorch_model.bin:  44%|████▍     | 2.71G/6.17G [00:10<00:13, 262MB/s]#015Downloading pytorch_model.bin:  44%|████▍     | 2.74G/6.17G [00:10<00:12, 274MB/s]#015Downloading pytorch_model.bin:  45%|████▍     | 2.77G/6.17G [00:10<00:12, 271MB/s]#015Downloading pytorch_model.bin:  45%|████▌     | 2.80G/6.17G [00:10<00:12, 272MB/s]#015Downloading pytorch_model.bin:  46%|████▌     | 2.83G/6.17G [00:10<00:11, 281MB/s]#015Downloading pytorch_model.bin:  46%|████▋     | 2.86G/6.17G [00:10<00:11, 280MB/s]#015Downloading pytorch_model.bin:  47%|████▋     | 2.89G/6.17G [00:10<00:12, 272MB/s]#015Downloading pytorch_model.bin:  47%|████▋     | 2.93G/6.17G [00:11<00:11, 276MB/s]#015Downloading pytorch_model.bin:  48%|████▊     | 2.96G/6.17G [00:11<00:11, 271MB/s]#015Downloading pytorch_model.bin:  48%|████▊     | 2.99G/6.17G [00:11<00:11, 273MB/s]#015Downloading pytorch_model.bin:  49%|████▉     | 3.03G/6.17G [00:11<00:11, 280MB/s]#015Downloading pytorch_model.bin:  50%|████▉     | 3.06G/6.17G [00:11<00:12, 251MB/s]#015Downloading pytorch_model.bin:  50%|█████     | 3.09G/6.17G [00:11<00:12, 256MB/s]#015Downloading pytorch_model.bin:  51%|█████     | 3.12G/6.17G [00:11<00:12, 250MB/s]#015Downloading pytorch_model.bin:  51%|█████     | 3.16G/6.17G [00:11<00:11, 252MB/s]#015Downloading pytorch_model.bin:  52%|█████▏    | 3.19G/6.17G [00:12<00:12, 247MB/s]#015Downloading pytorch_model.bin:  52%|█████▏    | 3.22G/6.17G [00:12<00:12, 242MB/s]#015Downloading pytorch_model.bin:  53%|█████▎    | 3.25G/6.17G [00:12<00:12, 236MB/s]#015Downloading pytorch_model.bin:  53%|█████▎    | 3.28G/6.17G [00:12<00:12, 235MB/s]#015Downloading pytorch_model.bin:  54%|█████▎    | 3.31G/6.17G [00:12<00:12, 232MB/s]#015Downloading pytorch_model.bin:  54%|█████▍    | 3.34G/6.17G [00:12<00:11, 243MB/s]#015Downloading pytorch_model.bin:  55%|█████▍    | 3.38G/6.17G [00:12<00:10, 255MB/s]#015Downloading pytorch_model.bin:  55%|█████▌    | 3.41G/6.17G [00:13<00:10, 261MB/s]#015Downloading pytorch_model.bin:  56%|█████▌    | 3.44G/6.17G [00:13<00:10, 267MB/s]#015Downloading pytorch_model.bin:  56%|█████▌    | 3.47G/6.17G [00:13<00:10, 268MB/s]#015Downloading pytorch_model.bin:  57%|█████▋    | 3.50G/6.17G [00:13<00:09, 270MB/s]#015Downloading pytorch_model.bin:  57%|█████▋    | 3.53G/6.17G [00:13<00:09, 274MB/s]#015Downloading pytorch_model.bin:  58%|█████▊    | 3.57G/6.17G [00:13<00:10, 256MB/s]#015Downloading pytorch_model.bin:  58%|█████▊    | 3.60G/6.17G [00:13<00:10, 251MB/s]#015Downloading pytorch_model.bin:  59%|█████▉    | 3.63G/6.17G [00:13<00:09, 256MB/s]#015Downloading pytorch_model.bin:  59%|█████▉    | 3.66G/6.17G [00:13<00:09, 265MB/s]#015Downloading pytorch_model.bin:  60%|█████▉    | 3.69G/6.17G [00:14<00:09, 265MB/s]#015Downloading pytorch_model.bin:  60%|██████    | 3.72G/6.17G [00:14<00:09, 264MB/s]#015Downloading pytorch_model.bin:  61%|██████    | 3.75G/6.17G [00:14<00:09, 263MB/s]#015Downloading pytorch_model.bin:  61%|██████▏   | 3.79G/6.17G [00:14<00:08, 266MB/s]#015Downloading pytorch_model.bin:  62%|██████▏   | 3.82G/6.17G [00:14<00:08, 269MB/s]#015Downloading pytorch_model.bin:  62%|██████▏   | 3.85G/6.17G [00:14<00:09, 257MB/s]#015Downloading pytorch_model.bin:  63%|██████▎   | 3.88G/6.17G [00:14<00:08, 270MB/s]#015Downloading pytorch_model.bin:  63%|██████▎   | 3.91G/6.17G [00:14<00:08, 271MB/s]#015Downloading pytorch_model.bin:  64%|██████▍   | 3.94G/6.17G [00:15<00:08, 264MB/s]#015Downloading pytorch_model.bin:  64%|██████▍   | 3.97G/6.17G [00:15<00:08, 266MB/s]#015Downloading pytorch_model.bin:  65%|██████▍   | 4.01G/6.17G [00:15<00:08, 263MB/s]#015Downloading pytorch_model.bin:  65%|██████▌   | 4.04G/6.17G [00:15<00:07, 273MB/s]#015Downloading pytorch_model.bin:  66%|██████▌   | 4.07G/6.17G [00:15<00:08, 261MB/s]#015Downloading pytorch_model.bin:  66%|██████▋   | 4.10G/6.17G [00:15<00:08, 246MB/s]#015Downloading pytorch_model.bin:  67%|██████▋   | 4.13G/6.17G [00:15<00:07, 260MB/s]#015Downloading pytorch_model.bin:  67%|██████▋   | 4.16G/6.17G [00:15<00:07, 273MB/s]#015Downloading pytorch_model.bin:  68%|██████▊   | 4.19G/6.17G [00:15<00:07, 280MB/s]#015Downloading pytorch_model.bin:  68%|██████▊   | 4.23G/6.17G [00:16<00:07, 258MB/s]#015Downloading pytorch_model.bin:  69%|██████▉   | 4.26G/6.17G [00:16<00:07, 249MB/s]#015Downloading pytorch_model.bin:  69%|██████▉   | 4.29G/6.17G [00:16<00:07, 254MB/s]#015Downloading pytorch_model.bin:  70%|██████▉   | 4.32G/6.17G [00:16<00:07, 250MB/s]#015Downloading pytorch_model.bin:  70%|███████   | 4.35G/6.17G [00:16<00:07, 252MB/s]#015Downloading pytorch_model.bin:  71%|███████   | 4.38G/6.17G [00:16<00:06, 257MB/s]#015Downloading pytorch_model.bin:  72%|███████▏  | 4.41G/6.17G [00:16<00:06, 259MB/s]#015Downloading pytorch_model.bin:  72%|███████▏  | 4.45G/6.17G [00:16<00:06, 258MB/s]#015Downloading pytorch_model.bin:  73%|███████▎  | 4.48G/6.17G [00:17<00:06, 258MB/s]#015Downloading pytorch_model.bin:  73%|███████▎  | 4.51G/6.17G [00:17<00:06, 262MB/s]#015Downloading pytorch_model.bin:  74%|███████▎  | 4.54G/6.17G [00:17<00:06, 267MB/s]#015Downloading pytorch_model.bin:  74%|███████▍  | 4.57G/6.17G [00:17<00:05, 274MB/s]#015Downloading pytorch_model.bin:  75%|███████▍  | 4.60G/6.17G [00:17<00:05, 270MB/s]#015Downloading pytorch_model.bin:  75%|███████▌  | 4.63G/6.17G [00:17<00:06, 247MB/s]#015Downloading pytorch_model.bin:  76%|███████▌  | 4.67G/6.17G [00:17<00:06, 250MB/s]#015Downloading pytorch_model.bin:  76%|███████▌  | 4.70G/6.17G [00:17<00:05, 254MB/s]#015Downloading pytorch_model.bin:  77%|███████▋  | 4.73G/6.17G [00:18<00:05, 258MB/s]#015Downloading pytorch_model.bin:  77%|███████▋  | 4.76G/6.17G [00:18<00:05, 268MB/s]#015Downloading pytorch_model.bin:  78%|███████▊  | 4.79G/6.17G [00:18<00:05, 274MB/s]#015Downloading pytorch_model.bin:  78%|███████▊  | 4.82G/6.17G [00:18<00:04, 276MB/s]#015Downloading pytorch_model.bin:  79%|███████▉  | 4.87G/6.17G [00:18<00:04, 292MB/s]#015Downloading pytorch_model.bin:  79%|███████▉  | 4.91G/6.17G [00:18<00:04, 300MB/s]#015Downloading pytorch_model.bin:  80%|███████▉  | 4.94G/6.17G [00:18<00:04, 298MB/s]#015Downloading pytorch_model.bin:  81%|████████  | 4.97G/6.17G [00:18<00:04, 277MB/s]#015Downloading pytorch_model.bin:  81%|████████  | 5.00G/6.17G [00:19<00:04, 268MB/s]#015Downloading pytorch_model.bin:  82%|████████▏ | 5.03G/6.17G [00:19<00:04, 256MB/s]#015Downloading pytorch_model.bin:  82%|████████▏ | 5.06G/6.17G [00:19<00:04, 242MB/s]#015Downloading pytorch_model.bin:  83%|████████▎ | 5.10G/6.17G [00:19<00:04, 250MB/s]#015Downloading pytorch_model.bin:  83%|████████▎ | 5.13G/6.17G [00:19<00:04, 261MB/s]#015Downloading pytorch_model.bin:  84%|████████▎ | 5.16G/6.17G [00:19<00:03, 267MB/s]#015Downloading pytorch_model.bin:  84%|████████▍ | 5.19G/6.17G [00:19<00:05, 179MB/s]#015Downloading pytorch_model.bin:  85%|████████▍ | 5.22G/6.17G [00:20<00:04, 196MB/s]#015Downloading pytorch_model.bin:  85%|████████▌ | 5.25G/6.17G [00:20<00:04, 212MB/s]#015Downloading pytorch_model.bin:  86%|████████▌ | 5.28G/6.17G [00:20<00:03, 224MB/s]#015Downloading pytorch_model.bin:  86%|████████▌ | 5.32G/6.17G [00:20<00:03, 232MB/s]#015Downloading pytorch_model.bin:  87%|████████▋ | 5.35G/6.17G [00:20<00:03, 251MB/s]#015Downloading pytorch_model.bin:  87%|████████▋ | 5.38G/6.17G [00:20<00:03, 248MB/s]#015Downloading pytorch_model.bin:  88%|████████▊ | 5.41G/6.17G [00:20<00:02, 261MB/s]#015Downloading pytorch_model.bin:  88%|████████▊ | 5.44G/6.17G [00:20<00:02, 261MB/s]#015Downloading pytorch_model.bin:  89%|████████▊ | 5.47G/6.17G [00:21<00:04, 160MB/s]#015Downloading pytorch_model.bin:  89%|████████▉ | 5.51G/6.17G [00:21<00:03, 179MB/s]#015Downloading pytorch_model.bin:  89%|████████▉ | 5.52G/6.17G [00:39<00:03, 179MB/s]#015Downloading pytorch_model.bin:  90%|████████▉ | 5.53G/6.17G [00:39<02:09, 4.99MB/s]#015Downloading pytorch_model.bin:  90%|█████████ | 5.56G/6.17G [00:40<01:24,\u001b[0m\n",
      "\u001b[34m 7.29MB/s]#015Downloading pytorch_model.bin:  91%|█████████ | 5.59G/6.17G [00:40<00:55, 10.5MB/s]#015Downloading pytorch_model.bin:  91%|█████████ | 5.62G/6.17G [00:40<00:36, 15.0MB/s]#015Downloading pytorch_model.bin:  92%|█████████▏| 5.65G/6.17G [00:40<00:24, 21.1MB/s]#015Downloading pytorch_model.bin:  92%|█████████▏| 5.68G/6.17G [00:40<00:16, 29.1MB/s]#015Downloading pytorch_model.bin:  93%|█████████▎| 5.71G/6.17G [00:40<00:11, 40.1MB/s]#015Downloading pytorch_model.bin:  93%|█████████▎| 5.75G/6.17G [00:40<00:07, 53.6MB/s]#015Downloading pytorch_model.bin:  94%|█████████▎| 5.78G/6.17G [00:40<00:05, 70.7MB/s]#015Downloading pytorch_model.bin:  94%|█████████▍| 5.81G/6.17G [00:41<00:03, 91.7MB/s]#015Downloading pytorch_model.bin:  95%|█████████▍| 5.84G/6.17G [00:41<00:02, 115MB/s] #015Downloading pytorch_model.bin:  95%|█████████▌| 5.87G/6.17G [00:41<00:02, 138MB/s]#015Downloading pytorch_model.bin:  96%|█████████▌| 5.90G/6.17G [00:41<00:01, 166MB/s]#015Downloading pytorch_model.bin:  96%|█████████▋| 5.95G/6.17G [00:41<00:01, 201MB/s]#015Downloading pytorch_model.bin:  97%|█████████▋| 5.98G/6.17G [00:41<00:00, 207MB/s]#015Downloading pytorch_model.bin:  97%|█████████▋| 6.01G/6.17G [00:41<00:00, 217MB/s]#015Downloading pytorch_model.bin:  98%|█████████▊| 6.04G/6.17G [00:41<00:00, 227MB/s]#015Downloading pytorch_model.bin:  98%|█████████▊| 6.07G/6.17G [00:42<00:00, 223MB/s]#015Downloading pytorch_model.bin:  99%|█████████▉| 6.10G/6.17G [00:42<00:00, 225MB/s]#015Downloading pytorch_model.bin:  99%|█████████▉| 6.13G/6.17G [00:42<00:00, 221MB/s]#015Downloading pytorch_model.bin: 100%|█████████▉| 6.17G/6.17G [00:42<00:00, 231MB/s]#015Downloading pytorch_model.bin: 100%|██████████| 6.17G/6.17G [00:42<00:00, 145MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)neration_config.json:   0%|          | 0.00/3.51k [00:00<?, ?B/s]#015Downloading (…)neration_config.json: 100%|██████████| 3.51k/3.51k [00:00<00:00, 20.2MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)okenizer_config.json:   0%|          | 0.00/800 [00:00<?, ?B/s]#015Downloading (…)okenizer_config.json: 100%|██████████| 800/800 [00:00<00:00, 7.01MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)olve/main/vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]#015Downloading (…)olve/main/vocab.json: 100%|██████████| 836k/836k [00:00<00:00, 38.9MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]#015Downloading (…)/main/tokenizer.json: 100%|██████████| 2.20M/2.20M [00:00<00:00, 66.1MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)olve/main/merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]#015Downloading (…)olve/main/merges.txt: 100%|██████████| 494k/494k [00:00<00:00, 26.4MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)main/normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]#015Downloading (…)main/normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 200MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]#015Downloading (…)in/added_tokens.json: 100%|██████████| 2.08k/2.08k [00:00<00:00, 18.0MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]#015Downloading (…)cial_tokens_map.json: 100%|██████████| 2.08k/2.08k [00:00<00:00, 18.1MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)rocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]#015Downloading (…)rocessor_config.json: 100%|██████████| 185k/185k [00:00<00:00, 154MB/s]\u001b[0m\n",
      "\u001b[34m/opt/ml/processing/input/test_video.mp4\u001b[0m\n",
      "\u001b[34mMoviePy - Writing audio in /opt/ml/processing/input/test_video.mp3\u001b[0m\n",
      "\u001b[34mMoviePy - Done.\u001b[0m\n",
      "\u001b[34m#015chunk:   0%|          | 0/9452 [00:00<?, ?it/s, now=None]#015chunk:   2%|▏         | 153/9452 [00:00<00:06, 1460.55it/s, now=None]#015chunk:   3%|▎         | 306/9452 [00:00<00:06, 1484.83it/s, now=None]#015chunk:   5%|▍         | 459/9452 [00:00<00:06, 1484.80it/s, now=None]#015chunk:   6%|▋         | 614/9452 [00:00<00:05, 1510.06it/s, now=None]#015chunk:   8%|▊         | 779/9452 [00:00<00:05, 1559.78it/s, now=None]#015chunk:  10%|▉         | 941/9452 [00:00<00:05, 1579.75it/s, now=None]#015chunk:  12%|█▏        | 1100/9452 [00:00<00:05, 1579.17it/s, now=None]#015chunk:  13%|█▎        | 1259/9452 [00:00<00:05, 1577.52it/s, now=None]#015chunk:  15%|█▌        | 1424/9452 [00:00<00:05, 1593.84it/s, now=None]#015chunk:  17%|█▋        | 1584/9452 [00:01<00:04, 1575.73it/s, now=None]#015chunk:  19%|█▊        | 1754/9452 [00:01<00:04, 1608.79it/s, now=None]#015chunk:  20%|██        | 1915/9452 [00:01<00:04, 1599.55it/s, now=None]#015chunk:  22%|██▏       | 2075/9452 [00:01<00:04, 1574.93it/s, now=None]#015chunk:  24%|██▎       | 2240/9452 [00:01<00:04, 1597.08it/s, now=None]#015chunk:  25%|██▌       | 2400/9452 [00:01<00:04, 1575.92it/s, now=None]#015chunk:  27%|██▋       | 2569/9452 [00:01<00:04, 1609.42it/s, now=None]#015chunk:  29%|██▉       | 2731/9452 [00:01<00:04, 1610.76it/s, now=None]#015chunk:  31%|███       | 2898/9452 [00:01<00:04, 1627.42it/s, now=None]#015chunk:  32%|███▏      | 3061/9452 [00:01<00:04, 1581.97it/s, now=None]#015chunk:  34%|███▍      | 3229/9452 [00:02<00:03, 1610.34it/s, now=None]#015chunk:  36%|███▌      | 3391/9452 [00:02<00:03, 1602.05it/s, now=None]#015chunk:  38%|███▊      | 3552/9452 [00:02<00:03, 1598.08it/s, now=None]#015chunk:  39%|███▉      | 3712/9452 [00:02<00:03, 1590.02it/s, now=None]#015chunk:  41%|████      | 3876/9452 [00:02<00:03, 1574.22it/s, now=None]#015chunk:  43%|████▎     | 4039/9452 [00:02<00:03, 1590.48it/s, now=None]#015chunk:  44%|████▍     | 4199/9452 [00:02<00:03, 1564.92it/s, now=None]#015chunk:  46%|████▌     | 4356/9452 [00:02<00:03, 1534.85it/s, now=None]#015chunk:  48%|████▊     | 4515/9452 [00:02<00:03, 1549.14it/s, now=None]#015chunk:  49%|████▉     | 4675/9452 [00:02<00:03, 1558.04it/s, now=None]#015chunk:  51%|█████     | 4831/9452 [00:03<00:03, 1535.22it/s, now=None]#015chunk:  53%|█████▎    | 4985/9452 [00:03<00:02, 1515.77it/s, now=None]#015chunk:  54%|█████▍    | 5144/9452 [00:03<00:02, 1536.03it/s, now=None]#015chunk:  56%|█████▌    | 5300/9452 [00:03<00:02, 1542.67it/s, now=None]#015chunk:  58%|█████▊    | 5457/9452 [00:03<00:02, 1520.88it/s, now=None]#015chunk:  59%|█████▉    | 5612/9452 [00:03<00:02, 1529.37it/s, now=None]#015chunk:  61%|██████    | 5769/9452 [00:03<00:02, 1540.36it/s, now=None]#015chunk:  63%|██████▎   | 5927/9452 [00:03<00:02, 1551.86it/s, now=None]#015chunk:  64%|██████▍   | 6083/9452 [00:03<00:02, 1541.53it/s, now=None]#015chunk:  66%|██████▌   | 6241/9452 [00:03<00:02, 1545.24it/s, now=None]#015chunk:  68%|██████▊   | 6398/9452 [00:04<00:01, 1552.40it/s, now=None]#015chunk:  69%|██████▉   | 6554/9452 [00:04<00:01, 1533.34it/s, now=None]#015chunk:  71%|███████   | 6714/9452 [00:04<00:01, 1548.10it/s, now=None]#015chunk:  73%|███████▎  | 6869/9452 [00:04<00:01, 1546.33it/s, now=None]#015chunk:  74%|███████▍  | 7026/9452 [00:04<00:01, 1546.27it/s, now=None]#015chunk:  76%|███████▌  | 7185/9452 [00:04<00:01, 1549.43it/s, now=None]#015chunk:  78%|███████▊  | 7344/9452 [00:04<00:01, 1535.77it/s, now=None]#015chunk:  79%|███████▉  | 7512/9452 [00:04<00:01, 1575.05it/s, now=None]#015chunk:  81%|████████  | 7670/9452 [00:04<00:01, 1574.63it/s, now=None]#015chunk:  83%|████████▎ | 7831/9452 [00:05<00:01, 1584.48it/s, now=None]#015chunk:  85%|████████▍ | 7990/9452 [00:05<00:00, 1578.87it/s, now=None]#015chunk:  86%|████████▌ | 8151/9452 [00:05<00:00, 1586.47it/s, now=None]#015chunk:  88%|████████▊ | 8313/9452 [00:05<00:00, 1564.81it/s, now=None]#015chunk:  90%|████████▉ | 8470/9452 [00:05<00:00, 1047.57it/s, now=None]#015chunk:  91%|█████████ | 8615/9452 [00:05<00:00, 1132.83it/s, now=None]#015chunk:  93%|█████████▎| 8761/9452 [00:05<00:00, 1208.32it/s, now=None]#015chunk:  94%|█████████▍| 8917/9452 [00:05<00:00, 1297.00it/s, now=None]#015chunk:  96%|█████████▌| 9064/9452 [00:05<00:00, 1341.20it/s, now=None]#015chunk:  98%|█████████▊| 9216/9452 [00:06<00:00, 1390.19it/s, now=None]#015chunk:  99%|█████████▉| 9368/9452 [00:06<00:00, 1426.05it/s, now=None]#015                                                                      #015#015Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]#015Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 9.18MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]#015Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.74MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]#015Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 67.6MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]#015Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<00:00, 5.35MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]#015Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 960kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]#015Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 34.8MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]#015Downloading pytorch_model.bin:  35%|███▍      | 31.5M/90.9M [00:00<00:00, 267MB/s]#015Downloading pytorch_model.bin:  69%|██████▉   | 62.9M/90.9M [00:00<00:00, 268MB/s]#015Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:00<00:00, 273MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]#015Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 304kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]#015Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 831kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 128MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]#015Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 3.18MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]#015Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 80.8MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 33.0MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]#015Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 3.06MB/s]\u001b[0m\n",
      "\u001b[34m['Amazon SageMaker is a fully managed machine learning service. With SageMaker, data scientists and developers can quickly and easily build and train machine learning models, and then directly deploy them into a production-ready hosted environment. It provides an integrated Jupyter authoring notebook instance for easy access for your data source for exploration and analysis. ', \"So you don't have to manage servers. It also provides common machine learning algorithms that are optimized to run efficiently against extremely large data in a distributed environment. With native support for bring your own algorithms and frameworks, SageMaker offers flexible distributed training options that adjust to your specific workloads. Deploy a model into a secure and scalable environment by launching it with a few clicks from SageMaker Studio or the SageMaker Console. Nation models are extremely powerful models able to solve a wide array of tasks. To solve most tasks efficiently, these models require some form of customization. The recommended way to first customize a foundation model to a specific use case is through prompt engineering. Providing your foundation model with well-engineered, context-rich prompts can help achieve desired results without any fine-tuning or changing of model weights. For more information, see prompt engineering for foundation models. If prompt engineering alone is not enough to customize your foundation model to a specific task, you can fine-tune the foundation model on additional domain-specific data. The fine-tuning process involves changing model weights. If you want to customize your model with information from a knowledge library without any retraining, see retrieval augmented generation. Prompt engineering is the process of designing and refining the prompts or input for a large model to generate specific types of output. Prompt engineering involves selecting appropriate keywords, providing context, and shaping the input in a way that encourages the model to produce the desired response and is the vital technique to actively shape the behavior and output of foundation models. Effective prompt engineering is crucial for directing model behavior and achieving desired responses. Through prompt engineering, you can control a model's tone, style, and domain expertise without more involved customization measures like fine-tuning. We recommend dedicating time to prompt engineering before you consider fine-tuning a model on additional data. The goal is to provide sufficient context and guidance to the model so that it can generalize and perform well on unseen or limited data scenarios. Find training a foundation model. Foundation models are computationally expensive and trend on a large unlabeled corpus. Fine-tuning a pre-trained foundation model is an affordable way to take advantage of their broad capabilities while customizing a model on your own small corpus. Fine-tuning is the customization method that involved further training and does change the weights of your model. Fun training might be useful to you if you need to customize your model to specific business needs, your model to successfully work with domain-specific language such as industry jargon, technical terms, or other specialized vocabulary. Enhanced performance for specific tasks. Accurate, relative, and context-aware responses in applications. \", 'Responses that are more factual, less toxic, and better aligned to specific requirement. There are two main approaches that you can take for fine-tuning depending on your use case and chosen foundation model. If you are interested in fine-tuning your model on domain-specific data, see domain adaptation fine-tuning. If you are interested in instruction-based fine-tuning using prompt and response expand pools, see instruction-based fine-tuning. Retrieval Augmented generation. Foundation models are usually trained offline, making the model agnostic to any data that is created after the model was trained. Additionally, foundation models are trained on very general domain corpora, making them less effective for domain-specific tasks. You can use Retrieval Augmented Generation, or RAG, to retrieve data from outside of foundation model and augment your prompts by adding the relevant retrieval data in context. For more information about RAG model architectures, see Retrieval Augmented Generation for Knowledge-Intensive NLP Tasks. With RAG, the external data used to augment your prompts can come from multiple data sources, such as a document repositories, databases, or APIs. The first step is to convert your documents and any user queries into a compatible format to perform relevancy search. To make the formats compatible, a document collection or knowledge library and user submitted queries are converted to numerical representations using embedding language models. Embedding is the process by which text is given numerical representation in the vector space. Rack model architectures compare the embeddings of user queries within the vector of the knowledge library. The original user prompt is then appended with relevant context from similar documents within the knowledge library. This augmented prompt is then sent to the foundation model. You can update knowledge libraries and their relevant embeddings asynchronously. ']\u001b[0m\n",
      "\u001b[34m/opt/ml/processing/input/test_audio.mp3\u001b[0m\n",
      "\n",
      "\u001b[34m[\"Thanks for watching! Bye for now. Today, we are happy to announce that we're beginning a new course. I'm Eriko Kojima. And I'm Michael Rees. And we're going to have fun learning useful expressions together. And then, you can try them out when you come to Japan. We'll also be talking about Japanese culture and places to visit. \", \"Today, asking for directions. Later in the program we'll talk about how the Japanese language sounds. The main character in our skit is Tam. She's a cheerful and active student from Vietnam. Tam studied Japanese on her own and can handle simple conversations. She wanted to learn more about the language and culture and the attractions of Japan's various regions. So she decided to come study at a university in Tokyo. In lesson one, Tam has just arrived in Japan for the first time and is trying to find Harusan House. It's the share house. University in Tokyo. where she'll be staying. A share house is a rented accommodation with multiple residents. Each has a private room but they all use common spaces such as the living room and the kitchen. That way they can interact with one another. \", \"A fashionable woman and a male student happened to walk by. so Tam decided to ask them for directions. Listen to the skit for lesson 1 to find out how things went. Excuse me, where is Harusan House. Harusan House. That's our house, right. It's close by. Let's go together. This way. Yes, thank you. Excuse me. Yes. Now, let's go over the skit line by line. Tam asks, Sumimasen. Excuse me. Harusan House wa doko desu ka. Where is Harusan House. Kaito, the male student, asks, Harusan House. Where is Harusan House. \", \"Kaito, the male student, asks. Harusan House. Harusan House. That's our house, isn't it. Oh, that's where we live. Then, Miya, the woman, says. Harusan house. That's our house, right. Oh, that's where we live. Then, Mia, the woman, says, It's close by. Let's go together. Kaito adds, This way. \", \"Tam replies, Okay, thank youatou gozaimasu. Okay, thank you very much. The two passers-by were residents of Harusan House. Today's key phrase is, Where is Harusan House. If you learn this pattern, you'll be able to ask for directions. Where is Harusan House. If you learn this pattern, you'll be able to ask for directions. Here's an explanation of the key phrase. Harusan House is the name of the share house. Wa is the particle indicating a topic. So, Eriko, what is a topic. It's a point of a conversation, what you're talking about. In this sentence, Harusan House is the topic. Doko desu ka. means where is. \", \"Today's point. When you want to ask for directions, add the particle WA after the name of the place and say, Doko desu ka. Doko is an interrogative meaning where. Adding desu ka and raising the intonation creates a question so you add what Doco Deska after the name of the place right that's right now let's practice. Listen and repeat. doko desu ka. Harusan House wa doko desu ka. So, how did you do. Next, listen to a conversation about asking for directions. Sumimasen. Sumimasen. Next. listen to a conversation about asking for directions. Let's review the conversation. Where is the toilet. When you want to ask someone a question, first start out with, Excuse me, sumimasen. The toilet is toire, which comes from the English word it sounds like. Asoko desu. It's over there. Asoko is over there. Various expressions tell you how to get somewhere. \", \"but people will also usually point in the general direction. so don't worry Now listen and repeat out loud toire wa doko desu ka. sumimasen, toire wa doko desu ka. Where is the toilet. Give it a try. If you want to find the way to the station, what do you say. Station is. Eki. Eki. Go ahead. Sumimasen. Eki wa doko desu ka. Now let's head for the convenience store. Convenience store is konbini konbini I'm sorry, but where is the convenience store. Were you able to say it right. \", \"Where is the next stop. That brings us up to today's bonus phrase. In this section, we introduce a phrase from the skit that will come in handy if you memorize it exactly as it is. Today's phrase is from Tam's line. ありがとうございます。 ありがとう phrase is from Tam's line. Arigatou gozaimasu. Arigatou gozaimasu is used to show appreciation, meaning thank you very much. You can use the shorter version, arigatou, but it's use the shorter version arigato but it's more polite to say arigato gozaimasu now it's your turn Arigato gozaimasu. Okay then, listen to today's skit once again. Excuse me, where is Harusan House. Harusan House. That's our house, right. It's close by. Let's go together. This way. \", \"Yes, thank you. So, Michael, what do you think about the sound of the Japanese language. Well, it seems like short sounds are linked. That's right. Most syllables in Japanese are made up of one consonant and one vowel. The language is smooth without many accents, so it may sound like someone is singing. What, no accents at all. Well, in general general the accent in Japanese comes from the pitch not strong or weak sounds. Each word has a set place where the pitch goes down. This determines the melody of the entire sentence. For example, ame ga furimashita means it rained. But if you pronounce it like this, ame ga furimashita this the meaning would be candy dropped. Really. Yes but don't worry even if you don't know the perfect pitch as long as you pronounce everything in a flat manner, it will sound good enough. Well, that's a relief. Japanese doesn't have that many sounds, so pronunciation is not that hard. After a while, the intonation will become second nature. Just keep your ears open. Okay I'll do that. So I'll do that. Did you enjoy today's Easy Japanese. You can access our website at wwwnhkorjp slash lesson slash en Tune in again next time dot jp slash lesson slash en. Tune in again next time. \"]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hfp.run(\n",
    "    code='preprocessing.py',\n",
    "    source_dir=\"data_preparation\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=s3_input, destination=\"/opt/ml/processing/input\")\n",
    "    ], \n",
    "    outputs=[\n",
    "        ProcessingOutput(source='/opt/ml/processing/output_clips', destination=s3_output_clips),\n",
    "        ProcessingOutput(source='/opt/ml/processing/transcripts', destination=s3_output_transcript),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--whisper-model\", \"whisper-large-v2\",\n",
    "        \"--target-language\", \"en\",\n",
    "        \"--sentence-embedding-model\", \"all-mpnet-base-v2\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7744aff0-7627-4091-942f-f0bb2ba3c30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('mytest'):\n",
    "    os.makedirs('mytest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efea032-76d4-478c-943a-a4be59d47ea7",
   "metadata": {},
   "source": [
    "## Deploy Whipser model to SageMaker for real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed73b43-b5c7-4e1a-bd15-8e020cab8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name=\"wisper-large-v2\"\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'openai/whisper-large-v2',\n",
    "    'HF_TASK':'automatic-speech-recognition',\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.26.0',\n",
    "    pytorch_version='1.13.1',\n",
    "    py_version='py39',\n",
    "    \n",
    "    env=hub,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00b59f-c17c-4446-a900-55e2835c5625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1, # number of instances\n",
    "    instance_type='ml.g5.xlarge' # ec2 instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3d59a-0ccf-4baf-95d9-a292c43872dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('runtime.sagemaker')\n",
    "file = \"test.mp3\"\n",
    "with open(file, \"rb\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8d3ec-15a3-4e5f-b85b-19dd5ce98dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='audio/x-audio', Body=data)\n",
    "output = json.loads(response['Body'].read())\n",
    "print(f\"Extracted text from the audio file:\\n {output['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3348fb1e-7c75-4641-85b6-234ba5348231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=f\"openai/whisper-large-v2\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fab02-5c19-47b8-b85e-7a138a080240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_kwargs = {\"task\":\"transcribe\", \"language\":f\"<|en|>\"}\n",
    "prediction = pipe(\n",
    "    'test_audio.mp3',\n",
    "    return_timestamps=True,\n",
    "    chunk_length_s=20,\n",
    "    stride_length_s=(5),\n",
    "    generate_kwargs=generate_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144673c0-79b0-45d0-bc24-b1b723032c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
